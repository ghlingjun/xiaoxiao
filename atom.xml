<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hakuna Matata</title>
  
  <subtitle>兴趣因你而生</subtitle>
  <link href="https://mp127.fun/atom.xml" rel="self"/>
  
  <link href="https://mp127.fun/"/>
  <updated>2024-11-28T05:30:14.000Z</updated>
  <id>https://mp127.fun/</id>
  
  <author>
    <name>Ethan</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>记一次读书会</title>
    <link href="https://mp127.fun/2024/11/28/reading-club/"/>
    <id>https://mp127.fun/2024/11/28/reading-club/</id>
    <published>2024-11-28T05:14:12.000Z</published>
    <updated>2024-11-28T05:30:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>上周六去参加了一场读书会，这几天总是时不时回味，就想最好还是记下来比较好。</p><p>起初周五时老婆发消息问我愿不愿意去参加读书会，我是比较排斥的。对于团体活动我都是既向往又排斥，排斥是因为有社交压力，向往是因为未知和不确定。这次决定去还是因为邀请的人，其实我们只见过几面，交流不多，给我的感觉就是温润如玉、学识渊博、乐于助人！</p><p>周六吃过午饭一家人就出发了，距离目的地紫蓬山东陶洼 30 多分钟的路程。今天天气很好，秋高气爽，集贤路两边树叶都黄了，一眼望去很美。紫庐空间是郑大哥租的地方，正对着一个方形大水塘，位置非常好，空间也够大，到的时候朋友正在给院外的萝卜浇水，也有人已经到了。非常惊讶整个房子与院子的设计，第一感觉是如果我年老了是不是也可以这样搞？两个孩子很开心，在院子里到处看。</p><img src="/2024/11/28/reading-club/yard.jpg" class="" title="小院"><img src="/2024/11/28/reading-club/wall-corner.jpg" class="" title="小院一角"><p>参加读书会的人陆续到达，大家都惊叹这里的环境和小院的美丽，大约 15 点一刻左右读书会开始。加上主持人一共 11 人，等真正开始时突然反应过来这其实是我第一次参加读书会。郑大哥主持，介绍了读书会的由来、主题，为什么取名”紫庐空间“，其实氛围还是挺轻松的，但也不失严肃。大家先自我介绍，然后是两位书友进行分享，分别是《救命饮食》和《卓有成效的管理者》。</p><p>《救命饮食》主要讲饮食与健康，不吃动物、低脂、深加工食物。其实饮食方面我个人没太多追求，平时饮食还是相对比较健康的，现阶段也很难一下就改为老师所讲的饮食方式，但很敬佩老师在推广健康饮食方面所做的事情。然后主持人补充讲的最触动我——善念，突然就想明白哪些能坚持吃素的人的动力在哪里了，这个善念应该是起了很大的作用。虽然大家偶尔会有小蚂蚁、小鸡、小鸭都是可爱的小动物，为什么会随意被杀死？意识到，讲出来，行动起来，最后到影响周围人，一步步都是思想上质的飞跃，深受触动的原因是他们在做第四步！</p><p>《卓有成效的管理者》我也读过两遍，但最近一次读也是去年了。今天听书友分享又受益匪浅！”有效性人人可学，但是无人可教“这句话让我醍醐灌顶，讲不清楚具体缘由，有种”纸上得来终觉浅，绝知此事要躬行“的感觉，但也不能完全表达自己的体会。还有一点是”我能贡献什么？“，这句话理解起来很简单，但是老师举的一个例子让我联想到自己更愿意独处的原因了，就是自己不善言辞，与人相处有时候就会感觉尴尬，也担心浪费别人时间。周老师关于这本书的其他解读也很有见地，是自己读的时候没有体会到的，我听得特别认真！很遗憾没有带纸笔，手机记录很不方便，想结束时最好要下他的 PPT 教材，再加深理解，后来忘记了！也感觉不大合适……</p><p>两位分享完差不多已 17 点多了，太阳已落山，本来讲茶歇时能欣赏日落的美景呢。15分钟左右时间的茶歇，大家去楼下吃一位参与者自己制作的面包，垫垫肚子，然后回去谈一谈读书会感受，差不多 18 点半左右读书会结束。大家陆续离开，本来想问下有什么收尾事情可以帮忙的，但是因为小路飞已经睡着了，也确实有些晚了就没有开口。临走时感谢了朋友的邀请，表达了收获很多，但是最后的感受讲的有些乱七八糟，朋友解围讲”意会就行，意会就行！“。回去的路上不自觉的就在不断回味，这个紫庐空间、读书会的意义。深深的感受到朋友他们那种博爱和宽广的胸怀，心里面更加的多佩服了几分！他们不止是做好自己，更在潜移默化的影响周围的人，为世界的更加美好真真实实的贡献更大力量。</p><p>现在一周都快过去了，脑袋里还是会无意识的的回味那天下午的体验。那句”意会就行“的客气话就很有道理，意会就像流行语说的”种草“，总会在心里慢慢成长……</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;上周六去参加了一场读书会，这几天总是时不时回味，就想最好还是记下来比较好。&lt;/p&gt;
&lt;p&gt;起初周五时老婆发消息问我愿不愿意去参加读书会，我是比较排斥的。对于团体活动我都是既向往又排斥，排斥是因为有社交压力，向往是因为未知和不确定。这次决定去还是因为邀请的人，其实我们只见过几</summary>
      
    
    
    
    <category term="blog" scheme="https://mp127.fun/categories/blog/"/>
    
    
    <category term="reading" scheme="https://mp127.fun/tags/reading/"/>
    
  </entry>
  
  <entry>
    <title>使用 rsync 服务备份 nas 数据</title>
    <link href="https://mp127.fun/2024/09/05/use-rsync-server-to-backup-nas/"/>
    <id>https://mp127.fun/2024/09/05/use-rsync-server-to-backup-nas/</id>
    <published>2024-09-05T07:18:31.000Z</published>
    <updated>2024-09-05T07:18:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>Nas 中的数据可通过 Hyper Backup 进行备份，Hyper Backup 可保留最多达 65,535 个版本的数据，同时通过跨版本重复数据删除功能，使存储空间消耗最小化。<br>备份的数据保留在一个拥有专利的数据库中，该数据库可通过 DSM、Windows 和 Linux 平台上专门设计的多版本资源管理器来浏览、下载或还原。<br>通过 Hyper Backup，可以将数据备份到本地&#x2F;远程 Synology NAS 设备，备份到远程 rsync、WebDav 和 OpenStack 服务器，备份到公有云。<br>这里介绍如何将数据备份到远程 rsync 服务器。</p><h1 id="首选需要配置-rsync-服务器"><a href="#首选需要配置-rsync-服务器" class="headerlink" title="首选需要配置 rsync 服务器"></a>首选需要配置 rsync 服务器</h1><h2 id="rsync-简介"><a href="#rsync-简介" class="headerlink" title="rsync 简介"></a>rsync 简介</h2><p>Rsync(remote synchronize) 是一个常用的 Linux 应用程序，用于文件同步。它可以同步本地和远程主机之间的文件。<br>与 FTP 或 scp 等其他文件传输工具不同，其最大的特点是：<br>会检查发送方和接收方已有的文件，仅传输有变动的部分（默认规则是文件大小或修改时间有变动）。</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>ubuntu 默认安装了 rsync。若备份服务器没有安装 rsync，可以用下面的命令安装。</p><pre><code class="bash"># Debain/Ubuntusudo apt install rsync# CentOSsudo yum install rsync</code></pre><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>Ubuntu 默认的配置文件位置：&#x2F;usr&#x2F;share&#x2F;doc&#x2F;rsync&#x2F;examples&#x2F;rsyncd.conf<br>需要将其复制到 &#x2F;etc&#x2F; 目录下。<br>配置示例：</p><pre><code class="text"># GLOBAL OPTIONS#motd file=/etc/motdlog file=/var/log/rsyncd# for pid file, do not use /var/run/rsync.pid if# you are going to run rsync out of the init.d script.# The init.d script does its own pid file handling,# so omit the &quot;pid file&quot; line completely in that case.pid file=/var/run/rsyncd.pidsyslog facility=daemon# MODULE OPTIONS[module_name]        comment = public archive        path = /home/username/backups/nas        use chroot = no        lock file = /var/lock/rsyncd        read only = no        list = yes        uid = username        gid = groupname        auth users = nas_user        secrets file = /etc/rsyncd.secrets        strict modes = yes        hosts allow = 10.10.1.190 10.10.1.189                ignore errors = yes        ignore nonreadable = yes        transfer logging = yes        timeout = 600        refuse options = checksum dry-run        dont compress = *.gz *.tgz *.zip *.z *.rpm *.deb *.iso *.bz2 *.tbz</code></pre><p>示例配置使用了验证权限的配置，需要建立：<br>&#x2F;etc&#x2F;rsyncd.secrets</p><pre><code class="text">nas_user:nas_password</code></pre><p>修改 rsyncd.secrets 访问权限为 600。</p><h2 id="启动-rsync-服务"><a href="#启动-rsync-服务" class="headerlink" title="启动 rsync 服务"></a>启动 rsync 服务</h2><p>配置完成后，启动 rsync 服务。</p><pre><code class="bash">sudo /etc/init.d/rsync start</code></pre><p>可在　&#x2F;etc&#x2F;default 路径下的 rsync 文件中将其改为自启动：<br><code>RSYNC_ENABLE=true</code></p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><pre><code class="shell">rsync -vzrtopg nas_user@10.10.1.9::module_name /home/shumei/backups/nasrsync -avz /mnt/d/honor.csv nas_user@10.10.1.9::module_namersync -avz /mnt/d/honor.csv nas_user@10.10.1.9::module_name --password-file=/etc/rsyncd.secrets</code></pre><h2 id="其次配置-Hyper-Backup"><a href="#其次配置-Hyper-Backup" class="headerlink" title="其次配置 Hyper Backup"></a>其次配置 Hyper Backup</h2><ul><li>从 nas 套件中心安装 Hyper Backup 套件。</li><li>打开新增备份任务向导，备份类型选择【文件夹和套件】，下一步。</li><li>备份目的地选择文件服务器中的【rsync】，下一步。</li><li>备份版本类型选择【多个版本】，下一步。</li><li>备份目的地设置：填写 ip、端口（默认 873）、用户名、密码、选择共享文件夹，然后下一步。</li><li>选择要备份的目录，然后点击【下一步】。</li><li>配置备份计划（每天运行一次；启用完整性检查，每周一次），然后点击【下一步】。</li><li>启用备份循环（Smart Recycle），保留版本的数量上限设置为 256，然后点击【完成】。</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://kb.synology.cn/zh-cn/DSM/help/HyperBackup/data_backup_source?version=7">https://kb.synology.cn/zh-cn/DSM/help/HyperBackup/data_backup_source?version=7</a><br><a href="https://www.cnblogs.com/felixzh/p/4950049.html">https://www.cnblogs.com/felixzh/p/4950049.html</a><br><a href="https://www.ruanyifeng.com/blog/2020/08/rsync.html">https://www.ruanyifeng.com/blog/2020/08/rsync.html</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Nas 中的数据可通过 Hyper Backup 进行备份，Hyper Backup 可保留最多达 65,535 个版本的数据，同时通过跨版本重复数据删除功能，使存储空间消耗最小化。&lt;br&gt;备份的数据保留在一个拥有专利的数据库中，该数据库可通过 DSM、Windows 和 </summary>
      
    
    
    
    <category term="运维" scheme="https://mp127.fun/categories/%E8%BF%90%E7%BB%B4/"/>
    
    <category term="nas" scheme="https://mp127.fun/categories/%E8%BF%90%E7%BB%B4/nas/"/>
    
    
    <category term="nas" scheme="https://mp127.fun/tags/nas/"/>
    
    <category term="rsync" scheme="https://mp127.fun/tags/rsync/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu 系统如何读取 CD？</title>
    <link href="https://mp127.fun/2024/08/02/how-to-read-cd/"/>
    <id>https://mp127.fun/2024/08/02/how-to-read-cd/</id>
    <published>2024-08-02T08:59:18.000Z</published>
    <updated>2024-08-02T08:59:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>在 Ubuntu 中，你可以使用命令行工具来读取光盘中的数据。以下是一个简单的步骤说明和示例代码：</p><ul><li>插入光盘到光驱。</li><li>打开终端。</li><li>使用 lsblk 命令来确定光盘的设备路径（例如：&#x2F;dev&#x2F;cdrom 或 &#x2F;dev&#x2F;sr0）。</li><li>如果需要，你可以挂载光盘到文件系统中，以便能够访问其数据。</li></ul><p>使用文件浏览器或命令行工具来读取光盘上的文件。</p><p>以下是一个示例命令序列，用于挂载光盘并复制其内容到当前目录：</p><pre><code class="shell"># 确定光盘设备，例如 /dev/cdrom 或 /dev/sr0lsblk# 创建一个挂载点，例如在 /mnt/cdromsudo mkdir /mnt/cdrom# 挂载光盘到这个挂载点sudo mount /dev/cdrom /mnt/cdrom# 复制光盘内容到当前目录cp -r /mnt/cdrom/. ./# 卸载光盘sudo umount /mnt/cdrom# 删除挂载点（如果不再需要）sudo rmdir /mnt/cdrom</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在 Ubuntu 中，你可以使用命令行工具来读取光盘中的数据。以下是一个简单的步骤说明和示例代码：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;插入光盘到光驱。&lt;/li&gt;
&lt;li&gt;打开终端。&lt;/li&gt;
&lt;li&gt;使用 lsblk 命令来确定光盘的设备路径（例如：&amp;#x2F;dev&amp;#x2F;c</summary>
      
    
    
    
    <category term="运维" scheme="https://mp127.fun/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="cd" scheme="https://mp127.fun/tags/cd/"/>
    
  </entry>
  
  <entry>
    <title>文章如何添加图片？</title>
    <link href="https://mp127.fun/2024/07/30/photo-bed/"/>
    <id>https://mp127.fun/2024/07/30/photo-bed/</id>
    <published>2024-07-30T04:41:07.000Z</published>
    <updated>2024-07-30T04:41:07.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>因为文章有少量图片需求，又不想使用三方存储资源，所以了解了使用 GitHub 作为图床的方法。具体操作方法如下：</p><h1 id="配置-Hexo-以使用文章资源文件夹"><a href="#配置-Hexo-以使用文章资源文件夹" class="headerlink" title="配置 Hexo 以使用文章资源文件夹"></a>配置 Hexo 以使用文章资源文件夹</h1><p>在 Hexo 的配置文件 <code>_config.yml</code> 中启用 post_asset_folder 功能：<code>post_asset_folder: true</code>。<br>该配置的作用：每次使用  ‘hexo new page’ 生成新文章，都会在文章文件同级目录创建一个与文章文件名同名的文件夹，我们就在这里存放此文章的所有图片和其他资源。<br>参考官方文档了解更多信息：<a href="https://hexo.io/zh-cn/docs/asset-folders">Hexo 官方文档 - 资源文件夹</a></p><h1 id="安装-hexo-asset-img-插件"><a href="#安装-hexo-asset-img-插件" class="headerlink" title="安装 hexo-asset-img 插件"></a>安装 hexo-asset-img 插件</h1><p>安装 <code>hexo-asset-img</code> 插件。</p><pre><code class="shell">npm install git://github.com/yiyungent/hexo-asset-img.git#main</code></pre><p>该插件作用：主要功能是处理 Markdown 文件中图片的路径，使文章发布后图片能正确显示。</p><h1 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h1><p>在 Markdown 文件中，图片路径使用如下格式：<code>![图片描述](文章名称/图片名称.jpg)</code>。其中，<code>文章名称</code> 表示当前文章同名的文件夹，<code>图片名称.jpg</code> 表示图片名称和后缀。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;因为文章有少量图片需求，又不想使用三方存储资源，所以了解了使用 GitHub 作为图床的方法。具体操作方法如下：&lt;/p&gt;
&lt;h1 id=&quot;配</summary>
      
    
    
    
    <category term="工具" scheme="https://mp127.fun/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="hexo" scheme="https://mp127.fun/categories/%E5%B7%A5%E5%85%B7/hexo/"/>
    
    
    <category term="hexo" scheme="https://mp127.fun/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop 学习笔记</title>
    <link href="https://mp127.fun/2024/07/26/hadoop-learning/"/>
    <id>https://mp127.fun/2024/07/26/hadoop-learning/</id>
    <published>2024-07-26T10:26:55.000Z</published>
    <updated>2024-07-26T10:26:55.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HDFS简介、设计目标和应用场景"><a href="#HDFS简介、设计目标和应用场景" class="headerlink" title="HDFS简介、设计目标和应用场景"></a>HDFS简介、设计目标和应用场景</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>HDFS（Hadoop Distributed File System） 是 Apache Hadoop 的核心组件之一，作为大数据生态圈最底层的分布式存储服务而存在。</p><p>HDFS 主要是解决大数据如何存储问题的。其是一种能够在普通硬件上运行的分布式文件系统，它是高容错的，适应于具有大数据集的应用程序，非常适合存储大型数据（比如TB和PB）。</p><p>HDFD 使用多台计算机存储文件，并且提供了统一的访问接口，像访问一个普通文件系统一样使用分布式文件系统。</p><h2 id="HDFS设计目标"><a href="#HDFS设计目标" class="headerlink" title="HDFS设计目标"></a>HDFS设计目标</h2><p>HDFS 可能有成千上百的服务器组成，每一个组件都有可能出现故障。因此故障检测和自动快速恢复是 HDFS 的核心架构目标。</p><p>HDFS 上的应用主要以流式读取数据（Streaming Data Access）。HDFS 因此被设计成用于批处理，而不是用户交互式的。相较于数据访问的反应时间，更注重数据访问的高吞吐量。</p><p>典型的 HDFS 文件大小是 GB 到 TB 的级别。所以 HDFS 被调整成支持大文件（Large Data Sets）。它应该提供很高的聚合数据带宽，一个集群中支持数百个节点，一个集群还应该支持千万级别的文件。</p><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><h3 id="适合场景"><a href="#适合场景" class="headerlink" title="适合场景"></a>适合场景</h3><p>大文件、数据流式访问、一次写入多次读取、低成本部署，廉价PC、高容错。</p><h3 id="不适合场景"><a href="#不适合场景" class="headerlink" title="不适合场景"></a>不适合场景</h3><p>小文件、数据交互式访问、频繁任意修改、低延迟处理。</p><h1 id="HDFS-重要特性解读"><a href="#HDFS-重要特性解读" class="headerlink" title="HDFS 重要特性解读"></a>HDFS 重要特性解读</h1><h2 id="主从架构集群"><a href="#主从架构集群" class="headerlink" title="主从架构集群"></a>主从架构集群</h2><p>一个 namenode 和一定数目的 datanode 组成。<br>namenode 是 HDFS 的主节点。管理元数据，记录每一个文件的信息，如何分块等信息。<br>datanode 是 HDFS 的从节点。存储 block 数据。</p><img src="/2024/07/26/hadoop-learning/hdfs-framework.png" class="" title="hdfs 架构图"><h2 id="分块存储"><a href="#分块存储" class="headerlink" title="分块存储"></a>分块存储</h2><p>HDFS 中的文件在物理上是分块（block）存储的，默认大小是 128M（134217728），不足 128M 的文件本身就是一块。</p><h2 id="副本机制"><a href="#副本机制" class="headerlink" title="副本机制"></a>副本机制</h2><p>文件的所有 block 都会有副本。副本系数可以在文件创建时可以指定，也可以在之后通过命令改变。<br>副本数由参数 dfs.replication 控制，默认值为 3，文件的所有 block 都会存储 3 份。</p><img src="/2024/07/26/hadoop-learning/3-copy-strategy.png" class="" title="3备份策略"><h2 id="元数据记录"><a href="#元数据记录" class="headerlink" title="元数据记录"></a>元数据记录</h2><p>namenode 管理的元数据有两种类型：</p><ol><li>文件自身属性信息：文件名称、权限、修改时间、文件大小、复制因子、数据块大小。</li><li>文件块位置映射信息：记录文件块 ID 等信息，及 datanode 之间的映射信息，即块位于哪个节点上。</li></ol><h2 id="抽象统一的目录树结构（namespace）"><a href="#抽象统一的目录树结构（namespace）" class="headerlink" title="抽象统一的目录树结构（namespace）"></a>抽象统一的目录树结构（namespace）</h2><p>HDFS 支持传统的层次型文件组织结构。文件系统的名字空间的层次结构与大多现有的文件系统雷系：用户可以创建、删除、移动或重命名文件。<br>namenode 负责维护文件系统的 namespace 名称空间，任何对文件系统名称空间或属性的修改都将被 namenode 记录下来。<br>HDFS 给客户端提供一个统一的抽象目录树，客户端通过路径来访问文件，形如：hdfs:&#x2F;&#x2F;namenode:port&#x2F;dir&#x2F;file.txt</p><h2 id="数据块存储"><a href="#数据块存储" class="headerlink" title="数据块存储"></a>数据块存储</h2><p>文件的各个 block 的具体存储管理由 datanode 节点承担。<br>每个 block 都可以在多个 datanode 上存储。</p><h1 id="HDFS-工作流程与机制——各角色职责"><a href="#HDFS-工作流程与机制——各角色职责" class="headerlink" title="HDFS 工作流程与机制——各角色职责"></a>HDFS 工作流程与机制——各角色职责</h1><img src="/2024/07/26/hadoop-learning/hdfs.png" class="" title="hdfs"><h2 id="主角色-namenode"><a href="#主角色-namenode" class="headerlink" title="主角色 namenode"></a>主角色 namenode</h2><ul><li>NameNode 是 Hadoop 分布式文件系统的核心，架构中的主角色。</li><li>NameNode 维护和管理文件系统元数据，包括名称空间目录树结构、文件和块的位置信息、访问权限等信息。</li><li>基于此，NameNode 成为了访问 HDFS 的唯一入口。</li><li>NameNode 内部通过内存和磁盘文件两种方式管理元数据。</li><li>其中磁盘上的元数据文件包括 Fsimage 内存元数据镜像文件和 edits log(Journal) 编辑日志。<img src="/2024/07/26/hadoop-learning/namenode.png" class="" title="namenode"></li></ul><h3 id="namenode-职责"><a href="#namenode-职责" class="headerlink" title="namenode 职责"></a>namenode 职责</h3><ul><li>NameNode 仅存储 HDFS 的元数据：文件系统中所有文件的目录树，并跟踪整个集群中的文件，不存储实际数据。</li><li>NameNode 知道 HDFS 中任何给定文件的块列表及其位置。使用此信息 NameNode 知道如何从块中构建文件。</li><li>NameNode 不持久化存储每个文件中各个块所在的 DataNode 的位置信息，这些信息会在系统启动时从 DataNode 重建。</li><li>NameNode 是 Hadoop 集群中的单点故障。</li><li>NameNode 所在机器通常会配置有大量内存（RAM）。</li></ul><h2 id="从角色-datanode"><a href="#从角色-datanode" class="headerlink" title="从角色 datanode"></a>从角色 datanode</h2><ul><li>DataNode 是 Hadoop HDFS 中的从角色，负责具体得数据快存储。</li><li>DataNode 的数量决定了 HDFS 集群的整体数据存储能力。通过和 NameNode 配合维护着数据块。<img src="/2024/07/26/hadoop-learning/datanodes.png" class="" title="datanodes"></li><li></li></ul><h3 id="datanode-职责"><a href="#datanode-职责" class="headerlink" title="datanode 职责"></a>datanode 职责</h3><ul><li>DataNode 负责最终数据块 block 的存储。是集群的从角色，也称为 Slave。</li><li>DataNode 启动时，会将自己注册到 NameNode 并汇报自己负责持有的块列表。</li><li>当某个 DataNode 关闭时，不会影响数据的可用性。NameNode 将安排由其他 DataNode 管理的块进行副本复制。</li><li>DataNode 所在的机器通常配置有大量的磁盘空间，因为实际数据存储在 DataNode 中。</li></ul><h2 id="主角色辅助角色-secondarynamenode"><a href="#主角色辅助角色-secondarynamenode" class="headerlink" title="主角色辅助角色 secondarynamenode"></a>主角色辅助角色 secondarynamenode</h2><ul><li>Secondary NameNode 充当 NameNode 的辅助节点，但不能替代 NameNode。</li><li>主要帮助主角色进行元数据文件的合并动作。可以通俗的理解为主角色的“秘书”。<img src="/2024/07/26/hadoop-learning/secondary-name-node.png" class="" title="主角色辅助角色"></li></ul><h1 id="HDFS-工作流程与机制——写数据流程——核心概念"><a href="#HDFS-工作流程与机制——写数据流程——核心概念" class="headerlink" title="HDFS 工作流程与机制——写数据流程——核心概念"></a>HDFS 工作流程与机制——写数据流程——核心概念</h1><h2 id="写数据流程图"><a href="#写数据流程图" class="headerlink" title="写数据流程图"></a>写数据流程图</h2><img src="/2024/07/26/hadoop-learning/write-data-flow.png" class="" title="写数据流程图"><h2 id="核心概念：Pipeline-管道"><a href="#核心概念：Pipeline-管道" class="headerlink" title="核心概念：Pipeline 管道"></a>核心概念：Pipeline 管道</h2><p>客户端将数据库写入第一个数据节点，第一个数据节点保存数据之后再将块复制到第二个数据节点，第二个数据节点保存后再将块复制到第三个数据节点。数据以管道方式，顺序的沿着一个方向传输，这样能够充分利用每个机器的贷款，避免网络瓶颈和高延时的连接，最小化推送所有数据的延时。</p><img src="/2024/07/26/hadoop-learning/pipline.png" class="" title="pipline"><h2 id="核心概念：ACK应答响应"><a href="#核心概念：ACK应答响应" class="headerlink" title="核心概念：ACK应答响应"></a>核心概念：ACK应答响应</h2><p>ACK（Acknowledge character），在数据通信中，接收方发给发送方的一种传输类控制字符。表示发来的数据已确认接收无误。<br>在 HDFS pipeline 传输数据过程中，传输的反方向会进行 ACK 校验，确保数据传输安全。</p><img src="/2024/07/26/hadoop-learning/ack.png" class="" title="ack应答响应"><h2 id="核心概念：默认三副本存储策略"><a href="#核心概念：默认三副本存储策略" class="headerlink" title="核心概念：默认三副本存储策略"></a>核心概念：默认三副本存储策略</h2><p>默认副本存储策略是由 BlockPlacementPolicyDefault 指定。<br>第一块副本：优先客户端本地，否则随机。<br>第二块副本：不同于第一块副本的不同机架。<br>第三块副本：第二块副本相同机架不同机器。</p><h1 id="HDFS-工作流程与机制——写数据流程——梳理"><a href="#HDFS-工作流程与机制——写数据流程——梳理" class="headerlink" title="HDFS 工作流程与机制——写数据流程——梳理"></a>HDFS 工作流程与机制——写数据流程——梳理</h1><ol><li><p>HDFS 客户端创建对象实例 DistributedFileSystem，该对象中封装了与 HDFS 文件系统操作的相关方法。</p></li><li><p>调用 DistributedFileSystem 对象的 create() 方法，通过 RPC 请求 NameNode 创建文件。</p><p>NameNode 执行各种检查判断：目标文件是否存在、父目录是否存在、客户端是否具有创建该文件的权限。检查通过 NameNode 就会为本次请求记录下一条记录，返回 FSDataOutputStream 输出流对象给客户端用于写数据。</p></li><li><p>客户端通过 FSDataOutputStream 输出流开始写入数据。</p></li><li><p>客户端写入数据时，将数据分成一个个数据包（packet 默认 64k），内部组件 DataStreamer 请求 NameNode 挑选出适合存储数据副本的一组 DataNode 地址，默认是 3 副本存储。</p><p>DataStreamer 将数据包流式传输到 pipeline 的第一个 DataNode, 该 DataNode 存储数据包并将它发送到 pipeline 的第二个 DataNode。同样，第二个 DataNode 存储数据包并且发送给第三个（也就是最后一个） DataNode。</p></li><li><p>传输的反方向上，会通过 ACK 机制校验数据包传输是否成功；</p></li><li><p>客户端完成数据写入后，在 FSDataOutputStream 输出流商调用 close() 方法关闭。</p></li><li><p>DistributedFileSystem 联系 NameNode 告知其文件写入完成，等待 NameNode 确认。<br>因为 NameNode 已经知道文件由哪些块组成（DataStream 请求分配数据块），因此仅需等待最小复制块即可返回成功。</p><p>最小复制是由参数 dfs.namenode.replication.min 指定，默认是 1。</p></li></ol><h1 id="MapReduce-的设计思想"><a href="#MapReduce-的设计思想" class="headerlink" title="MapReduce 的设计思想"></a>MapReduce 的设计思想</h1><h2 id="如何对付大数据处理场景"><a href="#如何对付大数据处理场景" class="headerlink" title="如何对付大数据处理场景"></a>如何对付大数据处理场景</h2><ol><li>对相互不具计算依赖关系的大数据计算任务，实现并行最自然的办法就是采用 MapReduce 分而治之的策略。</li><li>首先 Map 阶段进行拆分，把大数据拆分成若干份小数据，多个程序同时并行计算产生中间结果；然后是 Reduce 聚合阶段，通过程序对并行的结果进行最终的汇总计算，得出最终结果。<img src="/2024/07/26/hadoop-learning/map-reduce.png" class="" title="map-reduce"></li><li></li></ol><h2 id="构建抽象编程模型"><a href="#构建抽象编程模型" class="headerlink" title="构建抽象编程模型"></a>构建抽象编程模型</h2><p>MapReduce 借鉴了函数式语言中的思想，用 Map 和 Reduce 两个函数提供了高层的并行编程抽象模型。</p><p>map：对一组数据元素进行某种重复是的处理；</p><p>reduce：对 Map 的中间结果进行某种进一步的结果整理。</p><p>MapReduce 中定义了 Map 和 Reduce 两个抽象的编程接口，由用户去编程实现：</p><p>map: (k1:v1) -&gt; (k2:v2)</p><p>reduce: (k2:[v2]) -&gt; (k3:v3)</p><p>通过以上两个编程接口，可以看出 MapReduce 处理的数据类型是 &lt;key, value&gt; 键值对。</p><h2 id="统一架构、隐藏底层细节"><a href="#统一架构、隐藏底层细节" class="headerlink" title="统一架构、隐藏底层细节"></a>统一架构、隐藏底层细节</h2><p>如何提供统一的计算框架，如果没有统一封装底层细节，那么程序员则需要考虑诸如数据存储、划分、分发、结果收集、错误恢复等诸多细节；为此，MapReduce 设计并提供了统一的计算框架，为程序员隐藏了绝大多数系统层面的处理细节。</p><p>MapReduce 最大的亮点在于通过抽象模型和计算框架把需要做什么和具体怎么做分开了，为程序员提供了一个抽象和高层的编程接口和框架。</p><p>程序员仅需要关心其应用层的具体计算问题，仅需编写少量处理应用本身计算问题的业务程序代码。</p><p>至于如何具体完成这个并行计算任务所相关的诸多系统层细节被隐藏起来，交给框架去处理：从分布代码的执行，到大到数千小到单个节点集群的自动调度使用。</p><h1 id="MapReduce-介绍"><a href="#MapReduce-介绍" class="headerlink" title="MapReduce 介绍"></a>MapReduce 介绍</h1><p>MapReduce 是一个分布式计算框架，用于轻松编写分布式应用程序，这些应用程序以可靠、容错的方式并行处理大型硬件集群（数千个节点）上的大量数据（多TB数据集）。</p><p>MapReduce 是一种面向海量数据处理的一种指导思想，也是一种用于对大规模数据进行分布式计算的编程模型。</p><p>MapReduce 特点：易于编程；良好的扩展性；高容错性；适合海量数据的离线处理。</p><p>MapReduce 局限性：实时计算性能差；不能进行流式计算。</p><h2 id="MapReduce-实例进程"><a href="#MapReduce-实例进程" class="headerlink" title="MapReduce 实例进程"></a>MapReduce 实例进程</h2><p>一个完整的 MapReduce 程序在分布式运行时有三类：</p><p>MRAppMaster：负责整个 MR 程序的过程调度及状态协调</p><p>MapTask：负责 map 阶段的整个数据处理流程</p><p>ReduceTask：负责 reduce 阶段的整个数据处理流程</p><img src="/2024/07/26/hadoop-learning/map-reduce-instance-process.png" class="" title="MapReduce 实例进程"><h2 id="阶段组成"><a href="#阶段组成" class="headerlink" title="阶段组成"></a>阶段组成</h2><p>一个 MapReduce 编程模型中只能包含一个 Map 阶段和一个 Reduce 阶段，或者只有 Map 阶段。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;HDFS简介、设计目标和应用场景&quot;&gt;&lt;a href=&quot;#HDFS简介、设计目标和应用场景&quot; class=&quot;headerlink&quot; title=&quot;HDFS简介、设计目标和应用场景&quot;&gt;&lt;/a&gt;HDFS简介、设计目标和应用场景&lt;/h1&gt;&lt;h2 id=&quot;简介&quot;&gt;&lt;a hr</summary>
      
    
    
    
    <category term="读书" scheme="https://mp127.fun/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    <category term="Hadoop" scheme="https://mp127.fun/categories/%E8%AF%BB%E4%B9%A6/Hadoop/"/>
    
    
    <category term="Hadoop" scheme="https://mp127.fun/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>服务器性能监控及钉钉通知方案</title>
    <link href="https://mp127.fun/2024/07/12/server-performance-monitor/"/>
    <id>https://mp127.fun/2024/07/12/server-performance-monitor/</id>
    <published>2024-07-12T10:57:17.000Z</published>
    <updated>2024-07-12T10:57:17.000Z</updated>
    
    <content type="html"><![CDATA[<p>本方案实现思路是通过 shell 脚本查询服务器相关性能指标，并将性能指标记录下来，如果发现指标超出预设的阈值，则发送钉钉通知给相关人员。具体实现思路如下：</p><h1 id="创建脚本目录"><a href="#创建脚本目录" class="headerlink" title="创建脚本目录"></a>创建脚本目录</h1><p>使用如下命令创建所需目录：<br><code>mkdir -p /home/ethan/shell/log/monitor</code><br>使用<code>-p</code>选项，这样如果上层目录不存在，它会自动创建它们。其中用户目录<code>ethan</code>根据用户名修改。</p><h1 id="创建监控脚本"><a href="#创建监控脚本" class="headerlink" title="创建监控脚本"></a>创建监控脚本</h1><p>在<code>/home/ethan/shell</code>目录下创建 shell 脚本<code>server-monitor.sh</code>，内容参考附件【监控脚本】。</p><ul><li>修改脚本中服务器名称、磁盘目录等变量值；</li><li>修改脚本执行权限：<code>chmod 755 server-monitor.sh</code></li><li>测试脚本：<code>sh server-monitor.sh</code></li></ul><h1 id="创建定时任务"><a href="#创建定时任务" class="headerlink" title="创建定时任务"></a>创建定时任务</h1><p>执行<code>crontab -e</code>，添加定时任务，示例如下：</p><pre><code class="shell"># 服务器性能监控，每天 10:24 执行一次24 10 * * * sh /home/ethan/shell/server-monitor.sh &gt;&gt; /home/ethan/shell/crontab.log</code></pre><h1 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h1><h2 id="监控脚本"><a href="#监控脚本" class="headerlink" title="监控脚本"></a>监控脚本</h2><ol><li>脚本中常量<code>SERVER_NAME、DINGDING_ACCESS_TOKEN、DISK_PATH、LOG_PATH</code>值根据实际进行修改。</li><li>发送邮件通知可选。删掉函数 send_mail及两处调用代码即可禁用。启用发送邮件功能需要安装 mail组件，安装手册可参考文章 <a href="https://ghlingjun.github.io/xiaoxiao/2023/05/27/send-result-of-crontab-to-mail/">安装 mailutils</a>。</li></ol><pre><code class="shell">#!/bin/bash#定义主机名称SERVER_NAME=&quot;XX服务器&quot;# 要检测占用率的磁盘分区DISK_PATH=&quot;/home&quot;LOG_PATH=&quot;/home/ethan/shell/log/monitor&quot;# 钉钉机器人的 access_tokenDINGDING_ACCESS_TOKEN=access_token#可配置多个邮件接收者，使用,号分割RECIPIENT=&quot;ethan@163.com&quot;# 服务器性能监控，每天 10:24 执行一次# 24 10 * * * sh /home/ethan/shell/server-monitor.sh &gt;&gt; /home/ethan/shell/crontab.logDATE_STR=`date +%Y%m%d`echo &quot;--------------------------------------&quot;echo &quot;`date +&quot;%Y-%m-%d %H:%M:%S&quot;` 检测服务器性能指标开始！&quot;# 性能阈值DISK_THRESHOLD=80 # 磁盘使用率阈值（%）MEM_THRESHOLD=80 # 内存使用率阈值（%）CPU_THRESHOLD=80 # CPU使用率阈值（%）# 定义接收通知的钉钉机器人的 Webhook URL。DINGTALK_WEBHOOK_URL=&quot;https://oapi.dingtalk.com/robot/send?access_token=$&#123;DINGDING_ACCESS_TOKEN&#125;&quot;# 获取本机IP地址输出本机的ip地址LOCAL_IP=$(hostname -I | awk &#39;&#123;print $1&#125;&#39;)# 获取指定分区的磁盘占用率  $(df -h / | awk &#39;/\// &#123;print int($5)&#125;&#39;)DISK_USED=$(df -h $DISK_PATH | awk &#39;/\// &#123;print int($5)&#125;&#39;)# 获取当前系统的实际内存使用率（排除小数部分）MEM_USED=$(free | awk &#39;/Mem:/ &#123;print int($3/$2 * 100)&#125;&#39;)# 获取当前系统的CPU使用率（精确到个位）。获取当前系统的实际 CPU 使用率（排除空闲 CPU 百分比的影响）CPU_USED=$(top -bn 1 | grep &quot;Cpu(s)&quot; | awk &#39;&#123;print int(100 - $8)&#125;&#39;)log_path=&quot;$LOG_PATH/$&#123;DATE_STR&#125;.log&quot;send_mail() &#123;    cat &quot;$&#123;log_path&#125;&quot; | mail -s &quot;服务器($&#123;LOCAL_IP&#125;)性能指标&quot; &quot;$&#123;RECIPIENT&#125;&quot;&#125;echo &quot;--------------------------------------&quot; &gt;&gt; $&#123;log_path&#125;echo &quot;`date +&quot;%Y-%m-%d %H:%M:%S&quot;`&quot; &gt;&gt; $&#123;log_path&#125;# 判断是否超过告警阈值if [ $DISK_USED -gt $DISK_THRESHOLD ] || [ $MEM_USED -gt $MEM_THRESHOLD ] || [ $CPU_USED -gt $CPU_THRESHOLD ]; then    echo &quot;警告！性能监控发现问题！($&#123;SERVER_NAME&#125;) ($&#123;LOCAL_IP&#125;)&quot; &gt;&gt; $&#123;log_path&#125;    echo &quot;-----------------&quot; &gt;&gt; $&#123;log_path&#125;    echo &quot;磁盘已用：$DISK_USED%，其中占用率最多的前5个有：&quot; &gt;&gt; $&#123;log_path&#125;    echo &quot;`du -h --max-depth=1 $DISK_PATH | sort -rh | head -n 6`&quot; &gt;&gt; $&#123;log_path&#125;    echo &quot;-----------------&quot; &gt;&gt; $&#123;log_path&#125;    echo &quot;内存已用：$MEM_USED%，其中占用率最多的前5个有：&quot; &gt;&gt; $&#123;log_path&#125;    echo &quot;`ps -eo pid,%mem,cmd --sort=-%mem | head -n 6`&quot; &gt;&gt; $&#123;log_path&#125;    echo &quot;-----------------&quot; &gt;&gt; $&#123;log_path&#125;    echo &quot;CPU 已用：$CPU_USED%，其中占用率最多的前5个有：&quot; &gt;&gt; $&#123;log_path&#125;    echo &quot;`ps -eo pid,%cpu,cmd --sort=-%cpu | head -n 6`&quot; &gt;&gt; $&#123;log_path&#125;else    echo &quot;服务器($&#123;SERVER_NAME&#125;) ($&#123;LOCAL_IP&#125;)当前资源使用情况如下：&quot; &gt;&gt; $&#123;log_path&#125;    echo &quot;磁盘已用：$DISK_USED% 磁盘空间足够，无需担心&quot; &gt;&gt; $&#123;log_path&#125;    echo &quot;内存已用：$MEM_USED% 内存还很充足，无需担心&quot; &gt;&gt; $&#123;log_path&#125;    echo &quot;CPU已用：$CPU_USED% CPU运行正常，无需担心&quot; &gt;&gt; $&#123;log_path&#125;    # 每月1日将监控结果通过邮件发送给负责人    DAY_OF_WEEK=$(date +%u)    if [ &quot;$DAY_OF_WEEK&quot; -eq 1 ]; then        send_mail    fi    exit 1fiitem_monitor() &#123;    item_name=$1    item_used=$2    item_threshold=$3    item_command=$4    if [ $&#123;item_used&#125; -gt $&#123;item_threshold&#125; ]; then        echo &quot;-----------------&quot; &gt;&gt; $&#123;log_path&#125;        echo &quot;警告：$&#123;item_name&#125;资源使用率超出阈值！($&#123;SERVER_NAME&#125;) ($&#123;LOCAL_IP&#125;)&quot; &gt;&gt; $&#123;log_path&#125;        echo &quot;已用：$&#123;item_used&#125;% &quot; &gt;&gt; $&#123;log_path&#125;        echo &quot;查看占用率靠前的资源命令如下：&quot; &gt;&gt; $&#123;log_path&#125;        echo &quot;$&#123;item_command&#125;&quot; &gt;&gt; $&#123;log_path&#125;        # 通过钉钉机器人发送通知消息        curl -H &quot;Content-Type: application/json&quot; \            -d &#39;&#123;                &quot;msgtype&quot;: &quot;text&quot;,                &quot;text&quot;: &#123;                    &quot;content&quot;: &quot;【服务器监控】&#39;&quot;$&#123;item_name&#125;&quot;&#39; 占用率过高：(&#39;&quot;$&#123;item_used&#125;&quot;&#39;%) on (&#39;&quot;$&#123;SERVER_NAME&#125;&quot;&#39;) (&#39;&quot;$&#123;LOCAL_IP&#125;&quot;&#39;) at &#39;&quot;$(date)&quot;&#39;&quot;                &#125;            &#125;&#39; $DINGTALK_WEBHOOK_URL    fi&#125;item_monitor &quot;磁盘&quot; $&#123;DISK_USED&#125; $&#123;DISK_THRESHOLD&#125; &quot;du -h --max-depth=1 $&#123;DISK_PATH&#125; | sort -rh | head -n 6&quot;item_monitor &quot;内存&quot; $&#123;MEM_USED&#125; $&#123;MEM_THRESHOLD&#125; &quot;ps -eo pid,%mem,cmd --sort=-%mem | head -n 6&quot;item_monitor &quot;CPU&quot; $&#123;CPU_USED&#125; $&#123;CPU_THRESHOLD&#125; &quot;ps -eo pid,%cpu,cmd --sort=-%cpu | head -n 6&quot;send_mail# 参考资料# https://blog.csdn.net/qq_45547688/article/details/131804881# https://blog.csdn.net/zy_9466/article/details/132298199</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本方案实现思路是通过 shell 脚本查询服务器相关性能指标，并将性能指标记录下来，如果发现指标超出预设的阈值，则发送钉钉通知给相关人员。具体实现思路如下：&lt;/p&gt;
&lt;h1 id=&quot;创建脚本目录&quot;&gt;&lt;a href=&quot;#创建脚本目录&quot; class=&quot;headerlink&quot; t</summary>
      
    
    
    
    <category term="运维" scheme="https://mp127.fun/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="message" scheme="https://mp127.fun/tags/message/"/>
    
  </entry>
  
  <entry>
    <title>记一次 ssh 版本升级步骤</title>
    <link href="https://mp127.fun/2024/07/02/ssh-update/"/>
    <id>https://mp127.fun/2024/07/02/ssh-update/</id>
    <published>2024-07-02T11:10:54.000Z</published>
    <updated>2024-07-02T11:10:54.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="验证-ssh-依赖软件版本"><a href="#验证-ssh-依赖软件版本" class="headerlink" title="验证 ssh 依赖软件版本"></a>验证 ssh 依赖软件版本</h1><p>首先查看 openSSH 的安装说明，确定 openssl、zlib 的最低版本要求。例如 openssh-9.7p1 的要求如下：</p><pre><code class="text">A working installation of zlib:Zlib 1.1.4 or 1.2.1.2 or greater (earlier 1.2.x versions have problems):https://zlib.net/libcrypto from either of LibreSSL or OpenSSL.  Building without libcryptois supported but severely restricts the available ciphers and algorithms. - LibreSSL (https://www.libressl.org/) 3.1.0 or greater - OpenSSL (https://www.openssl.org) 1.1.1 or greaterLibreSSL/OpenSSL should be compiled as a position-independent library(i.e. -fPIC, eg by configuring OpenSSL as &quot;./config [options] -fPIC&quot;or LibreSSL as &quot;CFLAGS=-fPIC ./configure&quot;) otherwise OpenSSH will notbe able to link with it.  If you must use a non-position-independentlibcrypto, then you may need to configure OpenSSH --without-pie.If you build either from source, running the OpenSSL self-test (&quot;maketests&quot;) or the LibreSSL equivalent (&quot;make check&quot;) and ensuring that alltests pass is strongly recommended.NB. If you operating system supports /dev/random, you should configurelibcrypto (LibreSSL/OpenSSL) to use it. OpenSSH relies on libcrypto&#39;sdirect support of /dev/random, or failing that, either prngd or egd.</code></pre><p>从 openSSH 的安装说明中，可以得知，libcrypto 的最低版本要求是 LibreSSL 3.1.0 或 OpenSSL 1.1.1 或更高版本。<br>查看服务器上的 openssl 和 zlib 版本：</p><pre><code class="shell">openssl versionOpenSSL 1.1.1v  1 Aug 2023find /usr/ -name zlib.pc/usr/lib/x86_64-linux-gnu/pkgconfig/zlib.pc/usr/local/lib/pkgconfig/zlib.pc/usr/local/zlib/lib/pkgconfig/zlib.pccat /usr/lib/x86_64-linux-gnu/pkgconfig/zlib.pcprefix=/usrexec_prefix=$&#123;prefix&#125;libdir=$&#123;prefix&#125;/lib/x86_64-linux-gnusharedlibdir=$&#123;libdir&#125;includedir=$&#123;prefix&#125;/includeName: zlibDescription: zlib compression libraryVersion: 1.2.11Requires:Libs: -L$&#123;libdir&#125; -L$&#123;sharedlibdir&#125; -lzCflags: -I$&#123;includedir&#125;</code></pre><p>检查是否有 gcc 编译器：</p><pre><code class="shell">gcc --version# 如果没有的话安装apt-get install build-essential</code></pre><h1 id="下载安装包"><a href="#下载安装包" class="headerlink" title="下载安装包"></a>下载安装包</h1><p>openssh-9.7p1.tar.gz 下载<br><a href="https://mirrors.aliyun.com/pub/OpenBSD/OpenSSH/portable/openssh-9.7p1.tar.gz">https://mirrors.aliyun.com/pub/OpenBSD/OpenSSH/portable/openssh-9.7p1.tar.gz</a><br>openssl-1.1.1w.tar.gz 下载<br><a href="https://www.openssl.org/source/old/1.1.1/openssl-1.1.1w.tar.gz">https://www.openssl.org/source/old/1.1.1/openssl-1.1.1w.tar.gz</a><br>zlib 最新版本下载<br><a href="https://zlib.net/current/zlib.tar.gz">https://zlib.net/current/zlib.tar.gz</a></p><pre><code class="shell"># 上传到服务器scp openssh-9.7p1.tar.gz ethan@ip:/home/ethan/soft/</code></pre><h1 id="安装-openSSH"><a href="#安装-openSSH" class="headerlink" title="安装 openSSH"></a>安装 openSSH</h1><h2 id="备份-openSSH"><a href="#备份-openSSH" class="headerlink" title="备份 openSSH"></a>备份 openSSH</h2><pre><code class="shell">mkdir ~/backup/ssh/bak240328ls /etc/sshsudo mv /etc/ssh/* ~/backup/ssh/bak240328mkdir ~/backup/ssh/pamd240328ls /etc/pam.d/sshdsudo mv /etc/pam.d/sshd* ~/backup/ssh/pamd240328mkdir ~/backup/ssh/etcinitdbak240328ls /etc/init.d/ssh*sudo mv /etc/init.d/ssh* ~/backup/ssh/etcinitdbak240328/ls /usr/bin/ssh*sudo mv /usr/bin/ssh* ~/backup/ssh/# 停止 openSSH 服务sudo systemctl sshd.service stop</code></pre><h2 id="卸载-openSSH"><a href="#卸载-openSSH" class="headerlink" title="卸载 openSSH"></a>卸载 openSSH</h2><pre><code class="shell">sudo apt-get remove openssh-server openssh-client -y# orsudo apt purge --remove &quot;openssh*&quot;</code></pre><h2 id="安装-openSSH-1"><a href="#安装-openSSH-1" class="headerlink" title="安装 openSSH"></a>安装 openSSH</h2><pre><code class="shell">tar -xvzf openssh-9.7p1.tar.gzcd openssh-9.7p1# 编译配置./configure --prefix=/usr/local/openssh --sysconfdir=/etc/ssh  --with-ssl-dir=/usr/local/openssl --with-zlib-dir=/usr/local/zlib --without-openssl-header-check# 编译make# 安装sudo make installsudo ln -s /usr/local/openssh/bin/ssh /usr/local/bin/sshssh -V</code></pre><h2 id="将-openSSH-注册为服务"><a href="#将-openSSH-注册为服务" class="headerlink" title="将 openSSH 注册为服务"></a>将 openSSH 注册为服务</h2><pre><code class="shell">sudo vi /etc/systemd/system/sshd.service# /usr/lib/systemd/system/sshd.service# 添加以下内容：[Unit]Description=OpenSSH serverDocumentation=man:sshd(8) man:sshd_config(5)#After=network.target sshd-keygen.service#Wants=sshd-keygen.serviceAfter=network.target[Service]#Type=notify#EnvironmentFile=/etc/sysconfig/sshd#ExecStart=/usr/local/openssh/sbin/sshd -D $OPTIONSExecStart=/usr/local/openssh/sbin/sshd#ExecReload=/bin/kill -HUP $MAINPID#KillMode=process#Restart=on-failure#RestartSec=42s[Install]WantedBy=multi-user.target</code></pre><h2 id="重载-Systemctl-并设置为自启动"><a href="#重载-Systemctl-并设置为自启动" class="headerlink" title="重载 Systemctl, 并设置为自启动"></a>重载 Systemctl, 并设置为自启动</h2><pre><code class="shell">sudo systemctl enable sshdsudo systemctl daemon-reloadsudo systemctl start sshd.service</code></pre><h2 id="检查服务状态"><a href="#检查服务状态" class="headerlink" title="检查服务状态"></a>检查服务状态</h2><pre><code class="shell">systemctl status sshdnetstat -anpt | grep 22</code></pre><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><pre><code class="shell"># 手动启动 openSSHsudo /usr/local/openssh/sbin/sshd# 测试 scp 命令scp zlib.tar.gz ethan@ip:/home/ethan/</code></pre><h2 id="注册服务失败"><a href="#注册服务失败" class="headerlink" title="注册服务失败"></a>注册服务失败</h2><p>主要原因是 sshd.service 或者 ssh.service 冲突导致，主要查看以下两个目录：</p><pre><code class="shell">ls /etc/systemd/system/ssh*ls /usr/lib/systemd/system/ssh*</code></pre><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="https://ftp.openbsd.org/pub/OpenBSD/OpenSSH/portable/INSTALL">https://ftp.openbsd.org/pub/OpenBSD/OpenSSH/portable/INSTALL</a><br><a href="https://www.cnblogs.com/tangllty/p/18054446">https://www.cnblogs.com/tangllty/p/18054446</a><br><a href="https://blog.csdn.net/chsh4587/article/details/136328617">https://blog.csdn.net/chsh4587/article/details/136328617</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;验证-ssh-依赖软件版本&quot;&gt;&lt;a href=&quot;#验证-ssh-依赖软件版本&quot; class=&quot;headerlink&quot; title=&quot;验证 ssh 依赖软件版本&quot;&gt;&lt;/a&gt;验证 ssh 依赖软件版本&lt;/h1&gt;&lt;p&gt;首先查看 openSSH 的安装说明，确定 open</summary>
      
    
    
    
    <category term="运维" scheme="https://mp127.fun/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="ssh" scheme="https://mp127.fun/tags/ssh/"/>
    
  </entry>
  
  <entry>
    <title>防止域名被恶意解析</title>
    <link href="https://mp127.fun/2024/02/23/prevent-domain-names-from-being-maliciously-resolved/"/>
    <id>https://mp127.fun/2024/02/23/prevent-domain-names-from-being-maliciously-resolved/</id>
    <published>2024-02-23T10:17:51.000Z</published>
    <updated>2024-02-23T10:17:51.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="恶意域名解析的原理"><a href="#恶意域名解析的原理" class="headerlink" title="恶意域名解析的原理"></a>恶意域名解析的原理</h1><p>假如公网 IP 暴露，那么别人可以随意用一个域名解析到公网 IP，如果解析的域名未备案，那会有安全风险。那如何防止呢？下面是 Nignx 的解决办法：</p><p>如果 ip 对应的80（或者443）端口在 nginx 里没有指定默认资源，默认会以 conf.d 目录下的顺序第一的配置文件指向的资源为准，也就是用 80 或者 443 各排第一个的配置文件为默认资源。这时候如果用一个不相关的域名解析到 IP上，就会阴差阳错的关联到 conf.d 目录下 80 或者 443 各排第一位的配置文件对应的资源上。</p><p>防解析的解决方法也很简单，就是指定 80 和 443 端口的默认资源，让他们只返回 403 报错，默认资源没法显示有效内容，域名就没法解析成功。</p><h1 id="80-端口反代配置"><a href="#80-端口反代配置" class="headerlink" title="80 端口反代配置"></a>80 端口反代配置</h1><pre><code class="nginx">server &#123;    listen       80 default;    server_name  _;    return 403;&#125;</code></pre><h1 id="443-端口反代配置"><a href="#443-端口反代配置" class="headerlink" title="443 端口反代配置"></a>443 端口反代配置</h1><p>443 端口防范配置则需要配置 ssl 证书，否则所有 https 请求都会失败，下面是颁发自签名证书和配置过程。</p><h2 id="生成证书"><a href="#生成证书" class="headerlink" title="生成证书"></a>生成证书</h2><pre><code class="shell"># 首先，进入你想创建证书和私钥的目录，例如：cd /home/certs/# 创建服务器私钥，命令会让你输入一个口令：openssl genrsa -des3 -out server.key 2048# 创建签名请求的证书，最后两步密码留空（CSR）：openssl req -new -key server.key -out server.csr# 在加载 SSL 支持的 Nginx 并使用上述私钥时除去必须的口令：cp server.key server.key.orgopenssl rsa -in server.key.org -out server.key# 最后标记证书使用上述私钥和 CSR：openssl x509 -req -days 3650 -in server.csr -signkey server.key -out server.crt</code></pre><h2 id="配置-nginx"><a href="#配置-nginx" class="headerlink" title="配置 nginx"></a>配置 nginx</h2><p>在 nginx 目录下的 conf 目录内创建 403.conf：</p><pre><code class="nginx"># 防止域名被恶意解析server &#123;    listen       80 default;    server_name  403.abc.com;    return 403;    location ~/.well-known/acme-challenge/ &#123;        root /usr/share/nginx/html/;    &#125;&#125;server &#123;    listen       443 ssl default;    server_name  403.abc.com;    ssl_certificate      /etc/nginx/cert/server.crt;    ssl_certificate_key  /etc/nginx/cert/server.key;    ssl_session_timeout 5m;    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;    #表示使用的加密套件的类型。    ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #表示使用的TLS协议的类型。    ssl_prefer_server_ciphers on;    return 403;&#125;</code></pre><p>重启nginx，未报错，说明配置成功。</p><p>访问 <a href="http://ip/">http://ip</a> 返回 403，说明 80 端口的防解析配置成功！</p><p>访问 <a href="https://ip/">https://ip</a> 返回 403，说明 443 端口的防解析配置成功！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;恶意域名解析的原理&quot;&gt;&lt;a href=&quot;#恶意域名解析的原理&quot; class=&quot;headerlink&quot; title=&quot;恶意域名解析的原理&quot;&gt;&lt;/a&gt;恶意域名解析的原理&lt;/h1&gt;&lt;p&gt;假如公网 IP 暴露，那么别人可以随意用一个域名解析到公网 IP，如果解析的域名未备</summary>
      
    
    
    
    <category term="运维" scheme="https://mp127.fun/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="nginx" scheme="https://mp127.fun/tags/nginx/"/>
    
    <category term="dns" scheme="https://mp127.fun/tags/dns/"/>
    
  </entry>
  
  <entry>
    <title>为应用创建守护进程</title>
    <link href="https://mp127.fun/2023/09/21/use-systemd-manage-application/"/>
    <id>https://mp127.fun/2023/09/21/use-systemd-manage-application/</id>
    <published>2023-09-21T14:34:53.000Z</published>
    <updated>2023-09-21T14:34:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文介绍在 Linux 系统中，通过 systemd 来管理 Spring Boot 应用，实现当服务意外终止后自动重启。</p><h1 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h1><p>通过 systemd 管理 Spring Boot 应用，防止服务意外停止，增强可靠性。<br>可以实现开机自启并自动重启，意外停止自动重启等，守护线上应用。</p><h1 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h1><h2 id="1-创建服务文件"><a href="#1-创建服务文件" class="headerlink" title="1. 创建服务文件"></a>1. 创建服务文件</h2><p>在&#x2F;etc&#x2F;systemd&#x2F;system目录下创建一个文件，如 moon.service，内容如下：</p><pre><code class="text">[Unit]Description=moon data center service[Service]ExecStart=/home/ethan/software/jdk1.8.0_171/bin/java -server -Xms256m -Xmx1024m -Dfile.encoding=utf-8 -jar /home/ethan/servers/moon-admin/moon-admin-1.0.0-SNAPSHOT.jar &amp;Restart=on-failure[Install]WantedBy=multi-user.target</code></pre><blockquote><p>💡 Tips：Restart 参数可以设置为 always、on-failure。其中 always 表示程序异常退出时总是重启；on-failure 表示只在程序非正常退出时重启。</p></blockquote><h2 id="2-启动服务"><a href="#2-启动服务" class="headerlink" title="2.启动服务"></a>2.启动服务</h2><p><code>systemctl start moon</code></p><blockquote><p>💡 Tips：可以执行命令systemctl enable moon，来设定服务在开机启动。</p></blockquote><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>可以添加一些状态检查的脚本来确保应用已完全启动。另外还需要注意日志管理、资源分配等细节问题。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文介绍在 Linux 系统中，通过 systemd 来管理 Spring Boot 应用，实现当服务意外终止后自动重启。&lt;/p&gt;
&lt;h1 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h1&gt;&lt;p&gt;通</summary>
      
    
    
    
    <category term="运维" scheme="https://mp127.fun/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="systemd" scheme="https://mp127.fun/tags/systemd/"/>
    
  </entry>
  
  <entry>
    <title>jasypt spring boot</title>
    <link href="https://mp127.fun/2023/07/14/jasypt-spring-boot/"/>
    <id>https://mp127.fun/2023/07/14/jasypt-spring-boot/</id>
    <published>2023-07-14T10:34:53.000Z</published>
    <updated>2023-07-14T10:34:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文介绍如何将 jasypt 集成进 spring boot 项目中，用于解决用户、密码等敏感信息在代码中明文存储的问题。</p><h1 id="什么是-jasypt-spring-boot"><a href="#什么是-jasypt-spring-boot" class="headerlink" title="什么是 jasypt spring boot"></a>什么是 jasypt spring boot</h1><p><strong><a href="http://www.jasypt.org/">Jasypt</a></strong>  is a java library which allows the developer to add basic encryption capabilities to his&#x2F;her projects with minimum effort, and without the need of having deep knowledge on how cryptography works.</p><p>Jasypt 的特点请参看：<a href="http://www.jasypt.org/features.html">http://www.jasypt.org/features.html</a></p><h1 id="集成方法"><a href="#集成方法" class="headerlink" title="集成方法"></a>集成方法</h1><p><strong><a href="https://github.com/ulisesbocchio/jasypt-spring-boot">开源项目文档</a></strong> 中介绍了三种集成方式，本文仅详细介绍第一种详细集成方式（本文只做参考，应以开源项目文档未准）。</p><h2 id="三种集成方式"><a href="#三种集成方式" class="headerlink" title="三种集成方式"></a>三种集成方式</h2><h3 id="第一种"><a href="#第一种" class="headerlink" title="第一种"></a>第一种</h3><p>如果项目使用<code>@SpringBootApplication</code> 或者 <code>@EnableAutoConfiguration</code>，直接添加 jar 依赖即可。加密的配置项会在整个 Spring 项目中生效（This means any system property, environment property, command line argument, application.properties, application-*.properties, yaml properties, and any other property sources can contain encrypted properties）。</p><pre><code class="xml">&lt;dependency&gt;        &lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt;        &lt;artifactId&gt;jasypt-spring-boot-starter&lt;/artifactId&gt;        &lt;version&gt;3.0.5&lt;/version&gt;&lt;/dependency&gt;</code></pre><h3 id="第二种"><a href="#第二种" class="headerlink" title="第二种"></a>第二种</h3><p>如何项目中不使用自动配置注解 <code>@SpringBootApplication</code> 或<code>@EnableAutoConfiguration</code> ，那么添加如下依赖到项目中：</p><pre><code class="xml">&lt;dependency&gt;        &lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt;        &lt;artifactId&gt;jasypt-spring-boot&lt;/artifactId&gt;        &lt;version&gt;3.0.5&lt;/version&gt;&lt;/dependency&gt;</code></pre><p>再添加 <code>@EnableEncryptableProperties</code> 到你的 Configuration class. 示例：</p><pre><code class="java">@Configuration@EnableEncryptablePropertiespublic class MyApplication &#123;    ...&#125;</code></pre><p>这样加密配置项就会在整个 Spring 项目中生效（This means any system property, environment property, command line argument, application.properties, yaml properties, and any other custom property sources can contain encrypted properties）。</p><h3 id="第三种"><a href="#第三种" class="headerlink" title="第三种"></a>第三种</h3><p>如果项目中不使用自动装配注解 <code>@SpringBootApplication</code> or <code>@EnableAutoConfiguration</code> ，并且你也不想在整个 Spring 项目中启用加密配置，有第三种配置方式可以满足。首先添加下面依赖到项目中：</p><pre><code class="xml">&lt;dependency&gt;        &lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt;        &lt;artifactId&gt;jasypt-spring-boot&lt;/artifactId&gt;        &lt;version&gt;3.0.5&lt;/version&gt;&lt;/dependency&gt;</code></pre><p>然后在你的配置文件中根据需要添加注解<code>@EncryptablePropertySource</code>，就像添加 Spring 的注解<code>@PropertySource</code>一样，例如：</p><pre><code class="java">@Configuration@EncryptablePropertySource(name = &quot;EncryptedProperties&quot;, value = &quot;classpath:encrypted.properties&quot;)public class MyApplication &#123;    ...&#125;</code></pre><p>还有一个注解<code>@EncryptablePropertySources</code>，用于添加一组<code>@EncryptablePropertySource</code>注解，例如：</p><pre><code class="java">    @Configuration    @EncryptablePropertySources(&#123;@EncryptablePropertySource(&quot;classpath:encrypted.properties&quot;),                                 @EncryptablePropertySource(&quot;classpath:encrypted2.properties&quot;)&#125;)    public class MyApplication &#123;        ...    &#125;</code></pre><p>Also, note that as of version 1.8, <code>@EncryptablePropertySource</code> supports YAML files.</p><h2 id="集成详细步骤"><a href="#集成详细步骤" class="headerlink" title="集成详细步骤"></a>集成详细步骤</h2><h3 id="1-添加依赖"><a href="#1-添加依赖" class="headerlink" title="1. 添加依赖"></a>1. 添加依赖</h3><p>第一步添加依赖略，参看上面<strong>三种集成方式</strong>的第一种。</p><h3 id="2-添加加密配置项"><a href="#2-添加加密配置项" class="headerlink" title="2. 添加加密配置项"></a>2. 添加加密配置项</h3><p>在 application.yml 配置文件中添加如下配置项：</p><pre><code class="yaml">jasypt:  encryptor:    algorithm: PBEWITHHMACSHA512ANDAES_256    saltGeneratorClassName: org.jasypt.salt.RandomSaltGenerator    ivGeneratorClassName: org.jasypt.iv.RandomIvGenerator    property:      prefix: &quot;DC@[&quot;      suffix: &quot;]&quot;</code></pre><p>配置中的 prefix 和 suffix 是<strong>自定义</strong>的密码串标识。其中还有一个必须的参数<code>jasypt.encryptor.password</code>，用于加密。但为了安全需要通过命令行方式传入，不能放入配置文件中（<del>测试环境为了方便可以临时使用，但不能提交到代码仓库</del>）。启动命令示例：</p><pre><code class="yaml">java -Djasypt.encryptor.password=自己的加密秘钥 -jar xx.jar</code></pre><p>其中<code>自己的加密秘钥</code>是自定义密码字符串，推荐 32 为 md5 码。<strong>测试环境和生产环境不要用同一个秘钥</strong>。</p><p>如果使用 idea ，运行程序前需要在 Run&#x2F;Debug configuration 中的 VM option 中加入下面参数：</p><p><code>-Djasypt.encryptor.password=测试环境秘钥</code></p><h3 id="3-敏感信息加密"><a href="#3-敏感信息加密" class="headerlink" title="3. 敏感信息加密"></a>3. 敏感信息加密</h3><p>编写加密测试类如下：（**&#x3D;&#x3D;加密方法推荐使用附 1 中的脚本&#x3D;&#x3D;**）</p><pre><code class="java">package com.ahshumei.common.utils;import com.ahshumei.BaseTest;import org.jasypt.encryption.StringEncryptor;import org.junit.Test;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Value;import javax.annotation.Resource;/** * 对称加密算法测试类 * * @author ethan * @datetime 2023/7/14 14:01 */public class StringEncryptorTest extends BaseTest &#123;    protected Logger logger = LoggerFactory.getLogger(getClass());    @Resource    StringEncryptor stringEncryptor;    /**     * 对称加密测试方法     *     * @author ethan     * @datetime 2023/7/14 13:57     */    @Test    public void encryptTest() &#123;        String usernameEnc = stringEncryptor.encrypt(&quot;empower&quot;);        String passwordEnc = stringEncryptor.encrypt(&quot;teststr&quot;);        System.out.println(usernameEnc);        System.out.println(passwordEnc);        logger.info(&quot;test username encrypt is &#123;&#125;ª&quot;, usernameEnc);        logger.info(&quot;test password encrypt is &#123;&#125;&quot;, passwordEnc);        logger.info(&quot;test username is &#123;&#125;&quot;, stringEncryptor.decrypt(usernameEnc));        logger.info(&quot;test password is &#123;&#125;&quot;, stringEncryptor.decrypt(passwordEnc));    &#125;&#125;</code></pre><h3 id="4-配置加密项"><a href="#4-配置加密项" class="headerlink" title="4. 配置加密项"></a>4. 配置加密项</h3><p>将需要加密的配置项明文通过上一步测试方式进行加密，然后将加密后密文配置进配置文件中，示例：</p><pre><code class="yaml">spring:  datasource:    type: com.alibaba.druid.pool.DruidDataSource    driverClassName: com.mysql.cj.jdbc.Driver    druid:      # 主库数据源      master:        url: jdbc:mysql://10.10.1.7:3306/moon        username: DC@[4Y2s7d6D8rVQ3NAS/oWT+08QZT3dLcqN95i8YDtujnY6eFYshKGHDdniy7R5vyymª]        password: DC@[xImPkGcaY6qMK3vctVxkpKRg1KgxEG4hhMlgSQwiJhdueooHFGSUEccZFezeD2ig]</code></pre><p><code>DC@[]</code>占位符是上面配置文件中自定义配置的。</p><p>读取配置项测试类：</p><pre><code class="java">package com.ahshumei.common.utils;import com.ahshumei.BaseTest;import org.junit.Test;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Value;/** * 对称加密算法测试类 * * @author ethan * @datetime 2023/7/14 14:01 */public class StringEncryptorTest extends BaseTest &#123;    protected Logger logger = LoggerFactory.getLogger(getClass());    @Value(&quot;$&#123;spring.datasource.druid.master.username&#125;&quot;)    private String username;    @Value(&quot;$&#123;spring.datasource.druid.master.password&#125;&quot;)    private String password;    /**     * 测试读取加密配置项方法     *     * @author ethan     * @datetime 2023/7/14 18:13     */    @Test    public void decodeTest() &#123;        logger.info(username);        logger.info(password);    &#125;&#125;</code></pre><h3 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h3><p>jasypt 开源库为 Spring 项目提供了一种加解密能力来保护项目中的敏感信息，通过以上 4 步简单的配置即可使用，我们不需要去了解复杂加解密机制即可使用。并且 jasypt 不仅能集成到 Spring 中，还能集成到 Apache、Hibernate、SpringSecurity 等框架中。</p><h1 id="附-1：其他加密字符串生成方法"><a href="#附-1：其他加密字符串生成方法" class="headerlink" title="附 1：其他加密字符串生成方法"></a>附 1：其他加密字符串生成方法</h1><p>除了上面通过测试方法生成加密字符串外，还有以下两种更方便的方式：</p><h2 id="1-Java-命令行"><a href="#1-Java-命令行" class="headerlink" title="1 Java 命令行"></a>1 Java 命令行</h2><p>Jasypt提供了一个类专门用于加密解密，提供了main方法，调用如下：</p><pre><code class="shell">java -cp ./jasypt-1.9.3.jar org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI password=自己的加密秘钥 algorithm=PBEWithMD5AndTripleDES input=要加密的字符串</code></pre><h2 id="2-脚本"><a href="#2-脚本" class="headerlink" title="2 脚本"></a>2 脚本</h2><p>Jasypt为我们提供了脚本，可以直接用于加密解密，从 <a href="http://www.jasypt.org/download.html">http://www.jasypt.org/download.html</a> 可以下载（会引导到 github 项目中下载）。下载（jasypt-1.9.3-dist.zip）解压后的文件中有一个 bin 目录，其中有加密、解密的脚本。</p><p>脚本的使用方法与 java 命令一样，脚本本质上是封装了调用 java 类的工具。使用方法如下（参数含义参看<a href="http://www.jasypt.org/cli.html">官网文档</a>）：</p><pre><code class="shell">sh encrypt.sh password=自己的加密秘钥 algorithm=PBEWITHHMACSHA512ANDAES_256 saltGeneratorClassName=org.jasypt.salt.RandomSaltGenerator ivGeneratorClassName=org.jasypt.iv.RandomIvGenerator input=要加密的字符串</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文介绍如何将 jasypt 集成进 spring boot 项目中，用于解决用户、密码等敏感信息在代码中明文存储的问题。&lt;/p&gt;
&lt;h1 id=&quot;什么是-jasypt-spring-boot&quot;&gt;&lt;a href=&quot;#什么是-jasypt-spring-boot&quot; class</summary>
      
    
    
    
    <category term="工具" scheme="https://mp127.fun/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="jasypt" scheme="https://mp127.fun/tags/jasypt/"/>
    
  </entry>
  
  <entry>
    <title>发送定时任务执行结果到指定邮箱</title>
    <link href="https://mp127.fun/2023/05/27/send-result-of-crontab-to-mail/"/>
    <id>https://mp127.fun/2023/05/27/send-result-of-crontab-to-mail/</id>
    <published>2023-05-27T12:32:14.000Z</published>
    <updated>2023-07-18T12:32:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>在 Ubuntu 中，可以通过 crontab 服务的邮件功能，将定时任务的执行结果发送到指定邮箱。环境搭建方法如下：</p><h1 id="1-安装配置环境"><a href="#1-安装配置环境" class="headerlink" title="1 安装配置环境"></a>1 安装配置环境</h1><h2 id="1-1-安装-ssmtp-和-mailutils"><a href="#1-1-安装-ssmtp-和-mailutils" class="headerlink" title="1.1 安装 ssmtp 和 mailutils"></a>1.1 安装 ssmtp 和 mailutils</h2><pre><code class="shell">bash sudo apt install ssmtp mailutils</code></pre><p>配置过程需要选择配置类型，选择 <code>No configuration</code>。</p><p>安装好后需要配置两个文件：<code>/etc/ssmtp/ssmtp.conf /etc/ssmtp/revaliases</code></p><h2 id="1-2-修改配置"><a href="#1-2-修改配置" class="headerlink" title="1.2 修改配置"></a>1.2 修改配置</h2><h3 id="修改-ssmtp-配置文件"><a href="#修改-ssmtp-配置文件" class="headerlink" title="修改 ssmtp 配置文件"></a>修改 ssmtp 配置文件</h3><p>设置发送邮箱、SMTP服务器和端口等：</p><p><code>vi /etc/ssmtp/ssmtp.conf</code></p><pre><code class="shell"># Config file for sSMTP sendmail## The person who gets all mail for userids &lt; 1000# Make this empty to disable rewriting.root=postmaster# The place where the mail goes. The actual machine name is required no# MX records are consulted. Commonly mailhosts are named mail.domain.com#mailhub=smtp.aliyun.com:465mailhub=smtp.163.com:465# The full hostnamehostname=ubuntuUseTLS=Yes# Are users allowed to set their own From: address?# YES - Allow the user to specify their own From: address# NO - Use the system generated From: addressFromLineOverride=NO#邮箱名AuthUser=your_email@163.com#授权码AuthPass=authpassasdfasdf</code></pre><p>其中授权码 AuthPass 需要登录邮箱客户端获取。</p><h3 id="修改配置文件-revaliases"><a href="#修改配置文件-revaliases" class="headerlink" title="修改配置文件 revaliases"></a>修改配置文件 revaliases</h3><p><code>vi /etc/ssmtp/revaliases</code></p><pre><code class="shell"># sSMTP aliases## Format:       local_account:outgoing_address:mailhub## Example: root:your_login@your.domain:mailhub.your.domain[:port]# where [:port] is an optional port number that defaults to 25.# shumei 请修改为服务器用户名shumei:your_email@163.com:smtp.163.com:465</code></pre><p>至此邮件发送的环境已搭建完成。下面是编写脚本测试发送邮件。</p><h1 id="2-测试邮件发送"><a href="#2-测试邮件发送" class="headerlink" title="2 测试邮件发送"></a>2 测试邮件发送</h1><h2 id="2-1-编写任务脚本"><a href="#2-1-编写任务脚本" class="headerlink" title="2.1 编写任务脚本"></a>2.1 编写任务脚本</h2><p>在脚本中判断任务是否执行成功，如果失败则发送邮件。例如：</p><pre><code class="shell">bash#!/bin/bash# 执行任务some_command# 判断任务执行结果if [ $? -ne 0 ]; then    # 发送邮件,邮件内容为任务输出    echo &quot;Subject: Task Failed&quot; | mail -s &quot;Task Failed&quot; mailname@domain.comfi </code></pre><p>- <code>some_command</code> 替换为要执行的命令<br>- <code>$?</code> 用于获取上一条命令的返回值,如果不等于 0 表示失败<br>- <code>mail</code> 命令用于发送邮件<br>- <code>-s</code> 指定邮件主题<br>- <code>$MAIL</code> 为预先配置的接收邮箱环境变量</p><p>完成后为任务脚本添加可执行权限:<code>chmod +x script.sh</code></p><h2 id="2-2-添加定时任务"><a href="#2-2-添加定时任务" class="headerlink" title="2.2 添加定时任务"></a>2.2 添加定时任务</h2><p>在 crontab 文件中添加定时任务，例如:</p><pre><code class="shell">*/5 * * * * sh /path/to/script.sh   # 每5分钟执行一次</code></pre><p>当定时任务执行失败时，会发送一封邮件通知到您指定的邮箱，实现了只在任务失败时发送邮件的效果。</p><h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="https://blog.csdn.net/gmaaa123/article/details/137954791">https://blog.csdn.net/gmaaa123/article/details/137954791</a><br><a href="https://devpress.csdn.net/linux/62eba51020df032da732ba45.html">https://devpress.csdn.net/linux/62eba51020df032da732ba45.html</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在 Ubuntu 中，可以通过 crontab 服务的邮件功能，将定时任务的执行结果发送到指定邮箱。环境搭建方法如下：&lt;/p&gt;
&lt;h1 id=&quot;1-安装配置环境&quot;&gt;&lt;a href=&quot;#1-安装配置环境&quot; class=&quot;headerlink&quot; title=&quot;1 安装配置环境&quot;</summary>
      
    
    
    
    <category term="运维" scheme="https://mp127.fun/categories/%E8%BF%90%E7%BB%B4/"/>
    
    <category term="mail" scheme="https://mp127.fun/categories/%E8%BF%90%E7%BB%B4/mail/"/>
    
    
    <category term="ssmtp" scheme="https://mp127.fun/tags/ssmtp/"/>
    
    <category term="mailutils" scheme="https://mp127.fun/tags/mailutils/"/>
    
  </entry>
  
  <entry>
    <title>迁移 mysql 数据目录</title>
    <link href="https://mp127.fun/2023/05/25/migrate-mysql-data-directory/"/>
    <id>https://mp127.fun/2023/05/25/migrate-mysql-data-directory/</id>
    <published>2023-05-25T00:59:25.000Z</published>
    <updated>2023-05-25T00:59:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>在 CentOS 中迁移 MySQL 的数据目录 &#x2F;var&#x2F;lib&#x2F;mysql 到其他磁盘可以按以下步骤进行:</p><ol><li>停止MySQL服务</li></ol><pre><code class="shell">sudo service mysqld stop</code></pre><ol start="2"><li>新建目标数据目录，假设新的数据目录为 &#x2F;home&#x2F;mysql&#x2F;data，创建该目录：</li></ol><pre><code class="shell">sudo mkdir /home/mysql/data</code></pre><ol start="3"><li>将原数据目录中的内容复制到新目录</li></ol><pre><code class="shell">sudo cp -r /var/lib/mysql /home/mysql/data</code></pre><ol start="4"><li>修改新数据目录权限</li></ol><pre><code class="shell">sudo chown -R mysql:mysql /home/mysql/data/mysqlsudo chmod -R 755 /home/mysql/data/mysql</code></pre><ol start="5"><li>修改 MySQL 配置编辑MySQL配置文件 &#x2F;etc&#x2F;my.cnf，在 [mysqld] 部分添加：</li></ol><pre><code class="shell">log-bin = /home/mysql/data/mysql/hfgc-5-binlog_bin_index = /home/mysql/data/mysql/hfgc-5-bin.indexdatadir=/home/mysql/data/mysqlsocket=/home/mysql/data/mysql/mysql.sock</code></pre><p>将 datadir、log-bin 等相关项的值修改为新的数据目录路径。</p><ol start="6"><li>重新启动MySQL服务</li></ol><pre><code class="shell">sudo service mysqld start</code></pre><p> MySQL会自动使用新的 datadir 路径启动。</p><ol start="7"><li>检查 MySQL 是否正常运行进入 MySQL 命令行,检查数据库、表等是否正常：</li></ol><pre><code class="sql">show databases;use test; show tables;</code></pre><p>确认无异常后说明迁移成功。</p><ol start="8"><li>删除原数据目录（可选）确认迁移成功后可以删除原数据目录 &#x2F;var&#x2F;lib&#x2F;mysql。</li></ol><p>以上步骤通过修改配置、复制数据并修改权限的方式完成 MySQL 数据目录的迁移。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在 CentOS 中迁移 MySQL 的数据目录 &amp;#x2F;var&amp;#x2F;lib&amp;#x2F;mysql 到其他磁盘可以按以下步骤进行:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;停止MySQL服务&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&quot;shell&quot;&gt;sudo se</summary>
      
    
    
    
    <category term="运维" scheme="https://mp127.fun/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="mysql" scheme="https://mp127.fun/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>kettle experiences</title>
    <link href="https://mp127.fun/2023/05/23/kettle-experiences/"/>
    <id>https://mp127.fun/2023/05/23/kettle-experiences/</id>
    <published>2023-05-23T11:56:35.000Z</published>
    <updated>2023-05-23T11:56:35.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="kettle-部署"><a href="#kettle-部署" class="headerlink" title="kettle 部署"></a>kettle 部署</h1><ol><li>解压 pdi-ce 压缩包</li><li>放入 mysql 驱动至 lib 文件夹下</li><li>配置环境变量 .profile</li></ol><pre><code class="shell">export KETTLE=/home/shumei/soft/data-integrationexport PATH=$&#123;KETTLE&#125;:$PATH</code></pre><h1 id="经验"><a href="#经验" class="headerlink" title="经验"></a>经验</h1><h2 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h2><ul><li>日期转换</li></ul><pre><code class="sql">date_format(a.start_date, &#39;%Y/%m/%d 00:00:00.000&#39;) as start_datedate_format(create_time, &#39;%Y/%m/%d %T.%f&#39;) as data_create_timedate_format(a.payedDate, &#39;%Y/%m&#39;) as payedDatedate_format(DATE_ADD(now(), INTERVAL -1 MONTH), &#39;%Y%m&#39;);</code></pre><ul><li>日期计算</li></ul><pre><code class="sql">a.update_time &gt;= DATE_ADD(now(), INTERVAL -15 MINUTE)a.update_time &gt;= DATE_ADD(now(), INTERVAL -3 DAY)a.update_time &gt;= DATE_ADD(now(), INTERVAL -1 MONTH)a.update_time &gt;= DATE_ADD(now(), INTERVAL -1 YEAR)</code></pre><ul><li>类型转换</li></ul><pre><code class="sql"># 把字段 id 的类型转换为字符串 charCAST(id as CHAR) AS CODE</code></pre><h2 id="设定变量"><a href="#设定变量" class="headerlink" title="设定变量"></a>设定变量</h2><p>转换命名参数就是在转换内部定义的变量，作用范围是在转换内部。在转换的空白处双击左键，在转换属性中能看到“命名参数”。</p><p>引用：可以在表输入SQL语句中使用${变量名} 或者 %%变量名%%</p><h1 id="作业执行"><a href="#作业执行" class="headerlink" title="作业执行"></a>作业执行</h1><ul><li>执行转换</li></ul><pre><code class="shell">pan.sh -file tr1.ktrpan.sh -file tr1.ktr -param:year=2023 -param:month=5</code></pre><ul><li>执行作业</li></ul><pre><code class="shell">kitchen.sh -file jobname1.kjbkitchen.sh -file jobname2.kjb -param:input=/kettle -param:output=/kettle</code></pre><h1 id="定时任务脚本"><a href="#定时任务脚本" class="headerlink" title="定时任务脚本"></a>定时任务脚本</h1><pre><code class="shell">#!/bin/bash# 环境变量JAVA_HOME=/home/shumei/soft/jdk1.8.0_171KETTLE_HOME=&quot;/home/shumei/soft/data-integration&quot;export CLASSPATH=.:$&#123;JAVA_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin::$PATH# 公共变量DATE_STR=`date +%Y%m%d`;BASE_DIR=&#39;/home/shumei/kettle&#39;# 局部变量v_script_dir=&#39;/kettle/1015dca/pro&#39;v_shell_name=dca1mv_result=&quot;执行成功&quot;# 脚本名称JOB01_NAME=tr1.ktrJOB02_NAME=tr2.ktr# X 企业名录入库v_date_str=$(date +&quot;%Y-%m-%d %H:%M:%S&quot;)$&#123;KETTLE_HOME&#125;/pan.sh -file $&#123;BASE_DIR&#125;$&#123;v_script_dir&#125;/$&#123;v_job01_name&#125; -level=Basic &gt;&gt; $&#123;BASE_DIR&#125;/logs/$&#123;v_shell_name&#125;.$&#123;DATE_STR&#125;pan_return=$?if [ $pan_return -eq 0 ]; then    v_result=&quot;执行成功&quot;elif [ $pan_return -eq 1 ]; then    v_result=&quot;执行失败&quot;else    v_result=&quot;执行取消&quot;fiecho $v_resultif [ $pan_return -ne 0 ]; then    echo &quot;Task X 企业名录入库-$v_result $&#123;v_date_str&#125;&quot; | mail -s &quot;Subject: Task Failed&quot; ethan@ahshumei.comfiecho $&#123;v_date_str&#125;-X 企业名录入库 startecho -e $(date +&quot;%Y-%m-%d %H:%M:%S&quot;)-X 企业名录入库 end\nsleep 2</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;kettle-部署&quot;&gt;&lt;a href=&quot;#kettle-部署&quot; class=&quot;headerlink&quot; title=&quot;kettle 部署&quot;&gt;&lt;/a&gt;kettle 部署&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;解压 pdi-ce 压缩包&lt;/li&gt;
&lt;li&gt;放入 mysql 驱动至 </summary>
      
    
    
    
    <category term="工具" scheme="https://mp127.fun/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="kettle" scheme="https://mp127.fun/tags/kettle/"/>
    
  </entry>
  
  <entry>
    <title>联通云服务器初始化</title>
    <link href="https://mp127.fun/2022/07/14/cloud-server-init-cucloud/"/>
    <id>https://mp127.fun/2022/07/14/cloud-server-init-cucloud/</id>
    <published>2022-07-14T10:43:55.000Z</published>
    <updated>2022-07-14T10:43:55.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="挂载并格式化磁盘"><a href="#挂载并格式化磁盘" class="headerlink" title="挂载并格式化磁盘"></a>挂载并格式化磁盘</h1><p>查看磁盘<br>fdisk -l</p><p>格式化磁盘<br>sudo mkfs.ext4 &#x2F;dev&#x2F;vdb<br>mount &#x2F;dev&#x2F;vdb &#x2F;home</p><p>查看挂载结果<br>df -TH</p><h1 id="修改-root-密码"><a href="#修改-root-密码" class="headerlink" title="修改 root 密码"></a>修改 root 密码</h1><p>id # 查看用户信息<br>passwd # 修改用户密码</p><h1 id="修改-ssh-默认端口"><a href="#修改-ssh-默认端口" class="headerlink" title="修改 ssh 默认端口"></a>修改 ssh 默认端口</h1><p>sudo vi &#x2F;etc&#x2F;ssh&#x2F;sshd_config<br>修改 22 为 10021<br>Port 10021<br>重启 ssh 服务<br>sudo systemctl restart ssh</p><h1 id="创建用户组及用户"><a href="#创建用户组及用户" class="headerlink" title="创建用户组及用户"></a>创建用户组及用户</h1><p>[参考]<a href="https://www.cyberciti.biz/faq/howto-linux-add-user-to-group/">https://www.cyberciti.biz/faq/howto-linux-add-user-to-group/</a></p><pre><code># 查看用户组是否存在grep shumei /etc/group# 添加用户组 shumeigroupadd shumei# 查看用户 shumei 是否存在grep shumei /etc/passwd# 添加用户useradd -g shumei -d /home/shumei -m shumei# 查看 shumei 信息id shumei# 设置用户密码passwd shumei# 赋给用户 sudo 权限：http://man.linuxde.net/sudovi /etc/sudoers# 仿照现有root的例子就行，加一行（最好用tab作为空白）shumei  ALL=(ALL:ALL)   ALL</code></pre><p>Ubuntu 创建的用户为普通账户，默认 shell 为 &#x2F;bin&#x2F;sh，需要将账号的 shell 修改为 &#x2F;bin&#x2F;bash</p><pre><code># echo $SHELL 可查看当前使用的 shellusermod -s /bin/bash shumei</code></pre><h1 id="安装-JDK"><a href="#安装-JDK" class="headerlink" title="安装 JDK"></a>安装 JDK</h1><pre><code>scp jdk-8u25-linux-x64.tar.gz shumei@IP:port/pathvi .profileexport JAVA_HOME=/home/shumei/software/jdk1.8.0_25export CLASSPATH=.:$&#123;JAVA_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH# 使配置生效source .profile# 检查配置是否成功java -version</code></pre><h1 id="安装-Nginx"><a href="#安装-Nginx" class="headerlink" title="安装 Nginx"></a>安装 Nginx</h1><p>[请参考官网文档]<a href="https://nginx.org/en/linux_packages.html#Ubuntu">https://nginx.org/en/linux_packages.html#Ubuntu</a></p><h1 id="Redis安装"><a href="#Redis安装" class="headerlink" title="Redis安装"></a>Redis安装</h1><pre><code># 安装sudo apt install redis-server查看是否启动# redis-cli以上命令将打开以下终端：redis 127.0.0.1:6379&gt;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;挂载并格式化磁盘&quot;&gt;&lt;a href=&quot;#挂载并格式化磁盘&quot; class=&quot;headerlink&quot; title=&quot;挂载并格式化磁盘&quot;&gt;&lt;/a&gt;挂载并格式化磁盘&lt;/h1&gt;&lt;p&gt;查看磁盘&lt;br&gt;fdisk -l&lt;/p&gt;
&lt;p&gt;格式化磁盘&lt;br&gt;sudo mkfs.ext</summary>
      
    
    
    
    <category term="运维" scheme="https://mp127.fun/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="server" scheme="https://mp127.fun/tags/server/"/>
    
    <category term="联通云" scheme="https://mp127.fun/tags/%E8%81%94%E9%80%9A%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu 安装 SFTP 服务</title>
    <link href="https://mp127.fun/2021/11/23/ubuntu-sftp-install/"/>
    <id>https://mp127.fun/2021/11/23/ubuntu-sftp-install/</id>
    <published>2021-11-23T13:44:47.000Z</published>
    <updated>2021-11-23T13:44:47.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h1><p>在 Ubuntu 系统上开通 sftp 文件服务，允许指定用户上传及下载文件。但是这些用户只能使用 sftp 传输文件，不能使用 SSH 终端访问服务器，并且 sftp 不能访问系统文件。系统管理员则既能使用 sftp 传输文件，也能使用 SSH 远程管理服务器。<br>以下是将允许 sftp 用户组内的用户使用 sftp，但不允许使用 SSH Shell，且该组用户不能访问系统文件。</p><h1 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h1><h2 id="查看是否已安装-sftp"><a href="#查看是否已安装-sftp" class="headerlink" title="查看是否已安装 sftp"></a>查看是否已安装 sftp</h2><pre><code class="shell">dpkg --get-selections | grep ssh</code></pre><h2 id="新建-sftp-用户组"><a href="#新建-sftp-用户组" class="headerlink" title="新建 sftp 用户组"></a>新建 sftp 用户组</h2><pre><code class="shell"># 查看用户组是否存在grep sftp /etc/group# 添加用户组 sftpgroupadd sftp</code></pre><h2 id="新建-sftp-用户"><a href="#新建-sftp-用户" class="headerlink" title="新建 sftp 用户"></a>新建 sftp 用户</h2><pre><code class="shell"># 查看用户 sftp 是否存在grep sftp /etc/passwd# 添加用户useradd -g sftp -m sftp</code></pre><p>将 sftp 从所有其他用户组中移除并加入到 sftp 组，并且关闭其 Shell 访问：<br>sudo usermod -G sftp -s &#x2F;bin&#x2F;false sftp</p><h2 id="创建并设置-sftp-用户目录"><a href="#创建并设置-sftp-用户目录" class="headerlink" title="创建并设置 sftp 用户目录"></a>创建并设置 sftp 用户目录</h2><p>准备“监狱”的根目录及共享目录，“监狱”的根目录必须满足以下要求：<br>所有者为 root，其他任何用户都不能拥有写入权限。<br>因此，为了让 sftp 用户能够上传文件，还必须在“监狱”根目录下再创建一个普通用户能够写入的共享文件目录。</p><pre><code class="shell">sudo mkdir /home/sftpsudo mkdir /home/sftp/sharedsudo chown shumei:sftp /home/sftp/sharedsudo chmod 770 /home/sftp/shared</code></pre><h2 id="修改SSH配置文件"><a href="#修改SSH配置文件" class="headerlink" title="修改SSH配置文件"></a>修改SSH配置文件</h2><pre><code>vi  /etc/ssh/sshd_config注释内容：#Subsystem      sftp    /usr/libexec/openssh/sftp-server在文件的最后，添加以下内容：Subsystem       sftp    internal-sftpAllowGroups shumei sftpMatch Group sftpChrootDirectory /home/sftpAllowTcpForwarding noX11Forwarding noForceCommand internal-sftp -d shared</code></pre><p>这些内容的意思是：<br>只允许 shumei 及 sftp 通过SSH访问系统；<br>针对 sftp 用户，额外增加一些设置：<br>将“&#x2F;home&#x2F;sftp”设置为该组用户的系统根目录（因此它们将不能访问该目录之外的其他系统文件）；<br>禁止 TCP Forwarding 和X11 Forwarding；<br>强制该组用户仅仅使用 SFTP，“-d shared”默认用户登陆后自动进入 shared 目录。<br>如果需要进一步了解细节，可以使用“man sshd_config”命令。这样设置之后，SSH用户组可以访问SSH，并且不受其他限制；而SFTP用户组仅能使用SFTP进行访问，而且被关进监狱目录。</p><h2 id="设置-sftp-端口"><a href="#设置-sftp-端口" class="headerlink" title="设置 sftp 端口"></a>设置 sftp 端口</h2><p><code>sudo vim /etc/ssh/sshd_config</code></p><p>搜索以端口22开头的行。通常，该行使用井号(＃)注释掉。 删除哈希号，然后输入新的SSH端口号： Port 2222</p><p>编辑配置文件时要非常小心。 错误的配置可能会阻止SSH服务启动。</p><p>完成后，保存文件并重新启动SSH服务以使更改生效： <code>sudo systemctl restart ssh</code></p><h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><p>访问 sftp 服务：</p><pre><code class="shell">sftp -P 2222 sftp@127.0.0.1# 上传一个文件put local_file remote_fileput /home/user/test.txt /test/test_upload.txt# 下载一个文件get remote_file local_fileget /test/test.txt ~/Downloads/download.txt</code></pre><h1 id="使用-SSH-密钥对来访问-sftp-服务"><a href="#使用-SSH-密钥对来访问-sftp-服务" class="headerlink" title="使用 SSH 密钥对来访问 sftp 服务"></a>使用 SSH 密钥对来访问 sftp 服务</h1><p>首先为 sftp 用户创建 SSH 密钥对，然后将公钥添加到 sftp 用户的 SSH 允许列表中。这样 sftp 用户就可以使用 SSH 密钥对来访问 sftp 服务了。</p><h2 id="第一步查看已存在的密钥对"><a href="#第一步查看已存在的密钥对" class="headerlink" title="第一步查看已存在的密钥对"></a>第一步查看已存在的密钥对</h2><p>先检查是否已存在 SSH 密钥，SSH 密钥对一般存放在本地用户的根目录下。已存在本地公钥，你可以跳过生成 SSH 密钥。</p><p>ED25519 算法</p><pre><code class="shell">cat ~/.ssh/id_ed25519.pub</code></pre><p>RSA 算法</p><pre><code class="shell">cat ~/.ssh/id_rsa.pub</code></pre><p>如果返回一长串以 ssh-ed25519 或 ssh-rsa 开头的字符串, 说明已存在本地公钥，你可以跳过生成 SSH 密钥。如果不存在，参考第二步生成 SSH 密钥对。</p><h2 id="第二步生成-SSH-密钥对"><a href="#第二步生成-SSH-密钥对" class="headerlink" title="第二步生成 SSH 密钥对"></a>第二步生成 SSH 密钥对</h2><p>SSH 加密算法类型有 ED25519、RSA 等。</p><p>ED25519 是一种基于椭圆曲线密码学的数字签名算法，属于 EdDSA 签名方案的一部分。它使用 SHA-512&#x2F;256 散列函数和 Curve25519 椭圆曲线。由于其数学特性，ED25519 被认为是目前最安全、加解密速度最快的密钥类型之一。它的密钥长度比 RSA 小很多，因此具有更好的性能。然而，由于它的新颖性和复杂性，一些旧的软件或系统可能不支持 ED25519。</p><p>RSA 是一种广泛使用的公钥加密算法，既可以用于数据加密，也可以用于数字签名。RSA 的安全性基于大质数的难以分解性质。然而，随着计算机技术的发展，RSA 的安全性可能会受到威胁。RSA 密钥的长度通常比 ED25519 长，因此加解密速度相对较慢。但是，由于 RSA 的广泛使用和支持，它仍然是最兼容的密钥类型之一。</p><p>推荐使用 ED25519 算法生成 SSH 密钥对：</p><pre><code class="shell"># 注释会出现在.pub文件中，一般可使用邮箱作为注释内容，或者使用用户名作为注释内容ssh-keygen -t ed25519 -C &quot;&lt;注释内容&gt;&quot;</code></pre><p>基于 RSA 算法，生成密钥对命令如下：</p><pre><code class="shell">ssh-keygen -t rsa -C &quot;&lt;注释内容&gt;&quot;</code></pre><blockquote><p>警告：密钥用于鉴权，请谨慎保管。公钥文件以 .pub 扩展名结尾，可以公开给其他人，而没有 .pub 扩展名的私钥文件不要泄露给任何人！</p></blockquote><h2 id="第三步复制公钥"><a href="#第三步复制公钥" class="headerlink" title="第三步复制公钥"></a>第三步复制公钥</h2><p>查看公钥，然后复制到剪贴板</p><pre><code class="shell"># ED25519 算法cat ~/.ssh/id_ed25519.pub# 如果使用 RSA 算法生成密钥对，使用以下命令cat ~/.ssh/id_rsa.pub</code></pre><h2 id="第四步添加公钥"><a href="#第四步添加公钥" class="headerlink" title="第四步添加公钥"></a>第四步添加公钥</h2><p>将公钥添加到 sftp 用户的 SSH 允许列表中：</p><pre><code class="shell"># 添加公钥vi /home/sftp/.ssh/authorized_keys</code></pre><h2 id="测试确认"><a href="#测试确认" class="headerlink" title="测试确认"></a>测试确认</h2><p>测试确认是否可以使用 SSH 密钥对来访问 sftp 服务：</p><pre><code class="shell">sftp -P 2222 sftpuser@ip</code></pre><p>如果登陆成功，说明可以使用 SSH 密钥对来访问 sftp 服务了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;目标&quot;&gt;&lt;a href=&quot;#目标&quot; class=&quot;headerlink&quot; title=&quot;目标&quot;&gt;&lt;/a&gt;目标&lt;/h1&gt;&lt;p&gt;在 Ubuntu 系统上开通 sftp 文件服务，允许指定用户上传及下载文件。但是这些用户只能使用 sftp 传输文件，不能使用 SSH 终</summary>
      
    
    
    
    <category term="运维" scheme="https://mp127.fun/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="sftp" scheme="https://mp127.fun/tags/sftp/"/>
    
  </entry>
  
  <entry>
    <title>记 MySql 数据库被勒索病毒攻击</title>
    <link href="https://mp127.fun/2021/04/19/mysql-attacked-by-blackmail-virus/"/>
    <id>https://mp127.fun/2021/04/19/mysql-attacked-by-blackmail-virus/</id>
    <published>2021-04-19T05:37:42.000Z</published>
    <updated>2021-04-19T05:37:42.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="被勒索病毒攻击"><a href="#被勒索病毒攻击" class="headerlink" title="被勒索病毒攻击"></a>被勒索病毒攻击</h1><p>To recover your lost databases and avoid leaking it: visit <a href="http://o42xfh5kao7mrtesnok5jgdsfagjsgzxlxdlpkpd2x6lpckhzk225yad.onion/">http://o42xfh5kao7mrtesnok5jgdsfagjsgzxlxdlpkpd2x6lpckhzk225yad.onion</a> and enter your unique token e620354e995a068f and pay the required amount of Bitcoin to get it back. Databases that we have: emerge, dev_oa, wcjd_admin, oa, stock. Your databases are downloaded and backed up on our servers. If we dont receive your payment in the next 9 Days, we will sell your database to the highest bidder or use them otherwise. To access this site you have use the tor browser <a href="https://www.torproject.org/projects/torbrowser.html">https://www.torproject.org/projects/torbrowser.html</a></p><h1 id="解决过程"><a href="#解决过程" class="headerlink" title="解决过程"></a>解决过程</h1><h2 id="1-第一时间修改密码"><a href="#1-第一时间修改密码" class="headerlink" title="1. 第一时间修改密码"></a>1. 第一时间修改密码</h2><ol><li>修改服务器密码</li><li>修改数据库密码</li><li>修改数据库访问端口</li></ol><h2 id="2-确认数据恢复条件"><a href="#2-确认数据恢复条件" class="headerlink" title="2. 确认数据恢复条件"></a>2. 确认数据恢复条件</h2><p>数据恢复需要具备两个条件：</p><ol><li>有历史数据库备份文件；</li><li>MySql服务开启了 binlog；<br>若条件具备，才可进行数据恢复。</li></ol><h2 id="3-恢复方法"><a href="#3-恢复方法" class="headerlink" title="3. 恢复方法"></a>3. 恢复方法</h2><h3 id="1-查看binlog信息"><a href="#1-查看binlog信息" class="headerlink" title="1. 查看binlog信息"></a>1. 查看binlog信息</h3><p>show variables like ‘%log_bin%’;</p><p>备份 binlog 文件，防止日志文件丢失，binlog 文件目录可能为：&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;var，具体位置查询方式有两种：</p><ol><li>查询 MySql 配置文件 my.cnf，查看 binlog 路径配置项</li><li>通过 sql 命令查询</li></ol><pre><code># 查询当前主日志show master status; # 查询日志名为 binlog.000002 的相关信息，其中含日志路径show binlog events in &#39;binlog.000002&#39;;</code></pre><p>日志文件备份后，查询日志，确认数据被删除时间。先使用 mysqlbinlog 命令导出指定时间之后的日志信息：</p><pre><code>/usr/local/mysql/bin/mysqlbinlog --no-defaults --database=emerge --start-datetime=&quot;2021-04-16 17:46:14&quot; /home/shumei/sqllog/mysql-bin.000089 &gt; /home/shumei/sqllog/log89.sql</code></pre><p>若不知道 mysqlbinlog 命令位置，可通过 find 命令查找：</p><pre><code>find / -name mysqlbinlog</code></pre><p>输入日志后，查看日志内容如下：</p><pre><code># at 3809968#210416 17:46:19 server id 1  end_log_pos 3810094 Querythread_id=27527exec_time=0error_code=0use `emerge`/*!*/;SET TIMESTAMP=1618566379/*!*/;SET @@session.sql_mode=0/*!*/;CREATE TABLE whiteeyes (name VARCHAR(255), code VARCHAR(255))/*!*/;# at 3810094#210416 17:46:19 server id 1  end_log_pos 3810207 Querythread_id=27527exec_time=0error_code=0SET TIMESTAMP=1618566379/*!*/;DROP TABLE `whiteeyes` /* generated by server *//*!*/;# at 3810207#210416 17:48:59 server id 1  end_log_pos 3810294 Querythread_id=27529exec_time=0error_code=0SET TIMESTAMP=1618566539/*!*/;DROP DATABASE `emerge`/*!*/;# at 3810294#210416 17:49:01 server id 1  end_log_pos 3810448 Querythread_id=27530exec_time=0error_code=0SET TIMESTAMP=1618566541/*!*/;SET @@session.sql_mode=524288/*!*/;CREATE DATABASE IF NOT EXISTS `emerge` DEFAULT CHARACTER SET utf8 COLLATE utf8_unicode_ci/*!*/;# at 3810448#210416 17:49:02 server id 1  end_log_pos 3810736 Querythread_id=27530exec_time=0error_code=0use `emerge`/*!*/;SET TIMESTAMP=1618566542/*!*/;CREATE TABLE `WARNING`( `id` int(11) NOT NULL, `warning` text COLLATE utf8_unicode_ci, `website` text COLLATE utf8_unicode_ci, `token` text COLLATE utf8_unicode_ci) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci/*!*/;# at 3810736#210416 17:49:03 server id 1  end_log_pos 3810806 Querythread_id=27530exec_time=0error_code=0SET TIMESTAMP=1618566543/*!*/;BEGIN/*!*/;# at 3810806#210416 17:49:03 server id 1  end_log_pos 3811614 Querythread_id=27530exec_time=0error_code=0SET TIMESTAMP=1618566543/*!*/;INSERT INTO `WARNING` (`id`, `warning`, `website`, `token`) VALUES (1, &#39;To recover your lost databases and avoid leaking it: visit http://o42xfh5kao7mrtesnok5jgdsfagjsgzxlxdlpkpd2x6lpckhzk225yad.onion and enter your unique token e620354e995a068f and pay the required amount of Bitcoin to get it back. Databases that we have: emerge, dev_oa, wcjd_admin, oa, stock. Your databases are downloaded and backed up on our servers. If we dont receive your payment in the next 9 Days, we will sell your database to the highest bidder or use them otherwise. To access this site you have use the tor browser https://www.torproject.org/projects/torbrowser.html&#39;, &#39;http://o42xfh5kao7mrtesnok5jgdsfagjsgzxlxdlpkpd2x6lpckhzk225yad.onion&#39;, &#39;e620354e995a068f&#39;)</code></pre><p>确定数据库被删除时间为：210416 17:48:59，并根据日志推断需要恢复数据的时间点。</p><h3 id="2-根据推断确认恢复内容"><a href="#2-根据推断确认恢复内容" class="headerlink" title="2. 根据推断确认恢复内容"></a>2. 根据推断确认恢复内容</h3><p>导出日志内容：</p><pre><code>/usr/local/mysql/bin/mysqlbinlog --no-defaults --database=emerge --start-datetime=&quot;2020-10-13 11:15:52&quot; /home/shumei/sqllog/mysql-bin.000086 &gt; /home/shumei/sqllog/mysql_restore_86.sql/usr/local/mysql/bin/mysqlbinlog --no-defaults --database=emerge --start-datetime=&quot;2020-10-13 11:15:52&quot; /home/shumei/sqllog/mysql-bin.000087 &gt; /home/shumei/sqllog/mysql_restore_87.sql/usr/local/mysql/bin/mysqlbinlog --no-defaults --database=emerge /home/shumei/sqllog/mysql-bin.000088 &gt; /home/shumei/sqllog/mysql_restore_88.sql/usr/local/mysql/bin/mysqlbinlog --no-defaults --database=emerge --stop-datetime=&quot;2021-04-16 17:46:14&quot; /home/shumei/sqllog/mysql-bin.000089 &gt; /home/shumei/sqllog/mysql_restore_89.sql</code></pre><p>start-datetime 为拥有的最新数据库备份时间；<br>stop-datetime 为数据库被攻击时间；<br>日志导出后进行查看、确认，确定没问题可进行下一步数据恢复。</p><h3 id="3-恢复操作"><a href="#3-恢复操作" class="headerlink" title="3. 恢复操作"></a>3. 恢复操作</h3><ol><li>导入历史数据库备份。</li><li>通过 binlog 恢复备份时间至被攻击时间段内的数据。</li></ol><pre><code>/usr/local/mysql/bin/mysqlbinlog --no-defaults --database=emerge --start-datetime=&quot;2020-10-13 11:15:52&quot; /home/shumei/sqllog/mysql-bin.000087 | mysql -u root -p********/usr/local/mysql/bin/mysqlbinlog --no-defaults --database=emerge /home/shumei/sqllog/mysql-bin.000088 | mysql -u root -p********/usr/local/mysql/bin/mysqlbinlog --no-defaults --database=emerge --stop-datetime=&quot;2021-04-16 17:46:14&quot; /home/shumei/sqllog/mysql-bin.000089 | mysql -u root -p********</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;被勒索病毒攻击&quot;&gt;&lt;a href=&quot;#被勒索病毒攻击&quot; class=&quot;headerlink&quot; title=&quot;被勒索病毒攻击&quot;&gt;&lt;/a&gt;被勒索病毒攻击&lt;/h1&gt;&lt;p&gt;To recover your lost databases and avoid leaking i</summary>
      
    
    
    
    <category term="运维" scheme="https://mp127.fun/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="mysql" scheme="https://mp127.fun/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu Server 安装</title>
    <link href="https://mp127.fun/2021/03/29/install-Ubuntu-Server/"/>
    <id>https://mp127.fun/2021/03/29/install-Ubuntu-Server/</id>
    <published>2021-03-29T08:54:42.000Z</published>
    <updated>2021-03-29T08:54:42.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="下载系统-ISO-文件"><a href="#下载系统-ISO-文件" class="headerlink" title="下载系统 ISO 文件"></a>下载系统 ISO 文件</h1><p><a href="https://cn.ubuntu.com/download">https://cn.ubuntu.com/download</a><br>Ubuntu Server 20.04.2 LTS</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><ol><li>将 ISO 文件解压至 USB Disk 根目录</li><li>启动电脑时，进入手动选择模式（通常是 F12、F10、F2）</li><li>安装系统</li></ol><h1 id="配置静态IP"><a href="#配置静态IP" class="headerlink" title="配置静态IP"></a>配置静态IP</h1><p>查看IP</p><pre><code>ip addr</code></pre><p>修改配置文件</p><pre><code>vi /etc/netplan/00-installer-config.yaml# This is the network config written by &#39;subiquity&#39;network:  ethernets:    enp2s0:      dhcp4: no      addresses: [10.10.1.11/24]      gateway4: 10.10.1.1      nameservers:              addresses: [10.10.1.1]  version: 2</code></pre><h1 id="设置时区"><a href="#设置时区" class="headerlink" title="设置时区"></a>设置时区</h1><pre><code>修改配置文件vi .profile# 添加下面一行代码到最后TZ=&#39;Asia/Shanghai&#39;; export TZ</code></pre><h1 id="更新源"><a href="#更新源" class="headerlink" title="更新源"></a>更新源</h1><p>备份 sources.list<br>cd &#x2F;etc&#x2F;apt<br>sudo cp sources.list sources.list.bak</p><p>编辑 sources.list<br>添加如下内容（选择一个源即可）：</p><pre><code># tsinghuadeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted## Major bug fix updates produced after the final release of the## distribution.deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu## team. Also, please note that software in universe WILL NOT receive any## review or updates from the Ubuntu security team.deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy universedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates universe## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu## team, and may not be under a free licence. Please satisfy yourself as to## your rights to use the software. Also, please note that software in## multiverse WILL NOT receive any review or updates from the Ubuntu## security team.deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates multiverse## N.B. software from this repository may not have been tested as## extensively as that contained in the main release, although it includes## newer versions of some applications which may provide useful features.## Also, please note that software in backports WILL NOT receive any review## or updates from the Ubuntu security team.deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiversedeb http://security.ubuntu.com/ubuntu/ jammy-security main restricteddeb http://security.ubuntu.com/ubuntu/ jammy-security universedeb http://security.ubuntu.com/ubuntu/ jammy-security multiverse# 阿里源deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;下载系统-ISO-文件&quot;&gt;&lt;a href=&quot;#下载系统-ISO-文件&quot; class=&quot;headerlink&quot; title=&quot;下载系统 ISO 文件&quot;&gt;&lt;/a&gt;下载系统 ISO 文件&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://cn.ubuntu.com/dow</summary>
      
    
    
    
    <category term="运维" scheme="https://mp127.fun/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="ubuntu" scheme="https://mp127.fun/tags/ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>Eye of The Tiger</title>
    <link href="https://mp127.fun/2020/09/18/Eye-of-The-Tiger/"/>
    <id>https://mp127.fun/2020/09/18/Eye-of-The-Tiger/</id>
    <published>2020-09-18T05:38:56.000Z</published>
    <updated>2020-09-18T05:48:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>Eye of the Tiger 是 Survivor 乐队在 1982 年应西尔维斯特史泰龙为电影《洛奇3》创作的主题曲。</p><p>Risin’ up<br>back on the street<br>did my time took my chances<br>went the distance<br>now i’m back on my feet<br>just a man and and his will to survive<br>so many times<br>it happens too fast<br>you trade your passion for glory<br>don’t lose your grip on the dreams of the past<br>you must fight just to keep them alive<br>It’s the eye of the tiger<br>it’s the thrill of the fight<br>risin’ up to the challenge of our rival<br>and the last known survivor stalks his prey in the night<br>and he’s watchin us all with the eye<br>of the tiger<br>Face to face<br>out in the heat<br>hangin’ tough<br>stayin’ hungry<br>they stack the odds<br>still we take to the street<br>for the kill with the will to survive<br>It’s the eye of the tiger<br>it’s the thrill of the fight<br>risin’ up to the challenge of our rival<br>and the last known survivor stalks his prey in the night<br>and he’s watchin us all with the eye<br>of the tiger<br>Risin’ up<br>straight to the top<br>had the guts<br>got the glory<br>went the distance<br>now i’m not gonna stop<br>just a man and his will to survive<br>It’s the eye of the tiger<br>it’s the thrill of the fight<br>risin’ up to the challenge of our rival<br>and the last known survivor stalks his prey in the night<br>and he’s watchin us all with the eye<br>of the tiger</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Eye of the Tiger 是 Survivor 乐队在 1982 年应西尔维斯特史泰龙为电影《洛奇3》创作的主题曲。&lt;/p&gt;
&lt;p&gt;Risin’ up&lt;br&gt;back on the street&lt;br&gt;did my time took my chances&lt;br&gt;w</summary>
      
    
    
    
    <category term="blog" scheme="https://mp127.fun/categories/blog/"/>
    
    
    <category term="music" scheme="https://mp127.fun/tags/music/"/>
    
  </entry>
  
  <entry>
    <title>发布 docker 镜像</title>
    <link href="https://mp127.fun/2020/08/29/docker-push-image/"/>
    <id>https://mp127.fun/2020/08/29/docker-push-image/</id>
    <published>2020-08-29T09:39:58.000Z</published>
    <updated>2020-08-29T09:39:58.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="发布镜像到-docker-私服"><a href="#发布镜像到-docker-私服" class="headerlink" title="发布镜像到 docker 私服"></a>发布镜像到 docker 私服</h2><p>Dockerfile 示例：</p><pre><code># syntax=docker/dockerfile:experimentalFROM openjdk:8-jdk-alpine as buildWORKDIR /workspace/appCOPY target/bootstrap-1.0.0-SNAPSHOT.jar app.jarRUN mkdir -p target/dependency &amp;&amp; (cp app.jar target) &amp;&amp; (cd target/dependency; jar -xf ../*.jar)FROM openjdk:8-jdk-alpineVOLUME /tmpRUN addgroup -S ahshumei &amp;&amp; adduser -S ethan -G ahshumeiUSER ethan:ahshumeiARG DEPENDENCY=/workspace/app/target/dependencyCOPY --from=build $&#123;DEPENDENCY&#125;/BOOT-INF/lib /app/libCOPY --from=build $&#123;DEPENDENCY&#125;/META-INF /app/META-INFCOPY --from=build $&#123;DEPENDENCY&#125;/BOOT-INF/classes /appENTRYPOINT [&quot;java&quot;,&quot;-cp&quot;,&quot;app:app/lib/*&quot;,&quot;com.EmergencyManagementApplication&quot;]</code></pre><p>参考此示例时注意修改第四行jar包名称和最后一行的运行类名。</p><h3 id="1-打包"><a href="#1-打包" class="headerlink" title="1.打包"></a>1.打包</h3><pre><code>mvn -U clean package -Dmaven.test.skip=true或者指定打包模块命令：mvn -U clean package -Dmaven.test.skip=true -pl 模块名称 -am</code></pre><h3 id="–2-解压文件–"><a href="#–2-解压文件–" class="headerlink" title="–2.解压文件–"></a>–2.解压文件–</h3><pre><code>mkdir -p target/dependency &amp;&amp; (cd target/dependency; jar -xf ../*.jar)</code></pre><h3 id="3-创建镜像"><a href="#3-创建镜像" class="headerlink" title="3.创建镜像"></a>3.创建镜像</h3><pre><code>DOCKER_BUILDKIT=1 docker build -t ethan/镜像名 .</code></pre><h3 id="–4-创建容器–"><a href="#–4-创建容器–" class="headerlink" title="–4.创建容器–"></a>–4.创建容器–</h3><p>可在本地创建容器，用于测试镜像是否可正常使用。<br>指定端口、网络、以及配置文件创建并运行容器<br>docker run –name process -v &#x2F;opt&#x2F;docker_v&#x2F;application-cloud.yml:&#x2F;app&#x2F;application-cloud.yml -p 10100:10100 –net&#x3D;moon-network –ip&#x3D;172.127.0.100 -t ethan&#x2F;镜像名 –spring.profiles.active&#x3D;cloud<br>指定端口创建并运行容器<br>docker run –name process1 -p 10100:10100 -t ethan&#x2F;镜像名<br>将主机 &#x2F;opt&#x2F;docker_v&#x2F;application-cloud.yml 文件挂载到容器的 &#x2F;app&#x2F;application-cloud.yml 文件<br>-v &#x2F;opt&#x2F;docker_v&#x2F;application-cloud.yml:&#x2F;app&#x2F;application-cloud.yml</p><h3 id="5-发布镜像"><a href="#5-发布镜像" class="headerlink" title="5.发布镜像"></a>5.发布镜像</h3><p>docker login -u ethan harbor私服IP:端口<br>docker tag 镜像ID harbor私服IP:端口&#x2F;库名&#x2F;镜像名<br>docker push harbor私服IP:端口&#x2F;库名&#x2F;镜像名</p><h3 id="发布镜像到-docker-hub"><a href="#发布镜像到-docker-hub" class="headerlink" title="发布镜像到 docker hub"></a>发布镜像到 docker hub</h3><p>在docker hub 注册账号：<a href="https://hub.docker.com/repositories">https://hub.docker.com/repositories</a><br>使用Docker hub账号在验证本地登录：</p><pre><code>docker login</code></pre><p>修改 repository 名称，即 DockerID&#x2F;仓库名，不一致将无法发布：<br>docker tag 镜像ID 用户名称&#x2F;镜像源名(repository name):新的标签名(tag)<br>$ docker tag 487c260f20ee ethan2docker&#x2F;moon<br>docker push <your_username>&#x2F;my-first-repo:tag<br>$ docker push ethan2docker&#x2F;moon</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;发布镜像到-docker-私服&quot;&gt;&lt;a href=&quot;#发布镜像到-docker-私服&quot; class=&quot;headerlink&quot; title=&quot;发布镜像到 docker 私服&quot;&gt;&lt;/a&gt;发布镜像到 docker 私服&lt;/h2&gt;&lt;p&gt;Dockerfile 示例：&lt;/p&gt;</summary>
      
    
    
    
    <category term="工具" scheme="https://mp127.fun/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="docker" scheme="https://mp127.fun/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>docker compose 服务编排</title>
    <link href="https://mp127.fun/2020/08/23/docker-compose/"/>
    <id>https://mp127.fun/2020/08/23/docker-compose/</id>
    <published>2020-08-23T14:07:06.000Z</published>
    <updated>2020-08-23T14:07:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>安装 docker-compose</p><pre><code>sudo curl -L https://github.com/docker/compose/releases/download/1.22.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-compose</code></pre><p>验证：<br>docker-compose -version<br>PS：如果想要卸载docker-compose，请执行以下命令<br>sudo rm &#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker-compose</p><p>docker-compose 配置示例</p><pre><code>version: &#39;3&#39;services:  gc-admin:    build: ./spring-boot-admin    volumes:      - &quot;/opt/docker_v/application-cloud.yml:/app/application-cloud.yml&quot;    ports:      - &quot;10091:10091&quot;    networks:      gcnet:        ipv4_address: 172.127.0.91    environment:      spring.profiles.active: cloud#  redis:#    image: &quot;redis:alpine&quot;  networks:    gcnet:      external:        name: gc-network</code></pre><h3 id="构建"><a href="#构建" class="headerlink" title="构建"></a>构建</h3><pre><code>docker-compose build</code></pre><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><pre><code>docker-compose up -ddocker-compose ps</code></pre><p>The docker-compose run command allows you to run one-off commands for your services. For example, to see what environment variables are available to the web service:<br>$ docker-compose run web env</p><p>docker-compose stop<br>You can bring everything down, removing the containers entirely, with the down command. Pass –volumes to also remove the data volume used by the Redis container:<br>$ docker-compose down –volumes</p><p>docker-compose rm –force</p><h3 id="遇到问题"><a href="#遇到问题" class="headerlink" title="遇到问题"></a>遇到问题</h3><ol><li>http: server gave HTTP response to HTTPS client<br>解决办法：<br>在 &#x2F;etc&#x2F;docker 下，创建 daemon.json 文件，写入：</li></ol><pre><code>&#123;  &quot;debug&quot;: true,  &quot;experimental&quot;: false,  &quot;registry-mirrors&quot;: [    &quot;http://hub-mirror.c.163.com&quot;,    &quot;https://d4u3cjo2.mirror.aliyuncs.com&quot;  ],  &quot;insecure-registries&quot;: [    &quot;IP:PORT&quot; harbor私服的IP和端口  ]&#125;</code></pre><p>重启 docker：</p><pre><code>systemctl restart docker.servicesudo service docker restart</code></pre><p>docker启动日志：</p><pre><code>/var/log/upstart/docker.log</code></pre><h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p>Get started with Docker Compose[<a href="https://docs.docker.com/compose/gettingstarted/]">https://docs.docker.com/compose/gettingstarted/]</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;安装 docker-compose&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo curl -L https://github.com/docker/compose/releases/download/1.22.0/docker-compose-`uname -s`-`uname</summary>
      
    
    
    
    <category term="工具" scheme="https://mp127.fun/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="docker" scheme="https://mp127.fun/tags/docker/"/>
    
  </entry>
  
</feed>
